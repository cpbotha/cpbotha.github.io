<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>deep learning on voices in my head</title><link>https://cpbotha.net/tags/deep-learning/</link><description>Recent content in deep learning on voices in my head</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><managingEditor>cpbotha@cpbotha.net (Charl P. Botha)</managingEditor><webMaster>cpbotha@cpbotha.net (Charl P. Botha)</webMaster><lastBuildDate>Thu, 22 Nov 2018 20:20:39 +0000</lastBuildDate><atom:link href="https://cpbotha.net/tags/deep-learning/index.xml" rel="self" type="application/rss+xml"/><item><title>Weekly Head Voices #158: Charlie and the Chocolate Factory.</title><link>https://cpbotha.net/2018/11/22/weekly-head-voices-158-charlie-and-the-chocolate-factory/</link><pubDate>Thu, 22 Nov 2018 20:20:39 +0000</pubDate><author>cpbotha@cpbotha.net (Charl P. Botha)</author><guid>https://cpbotha.net/2018/11/22/weekly-head-voices-158-charlie-and-the-chocolate-factory/</guid><description> (Note that there’s now a Telegram group that you can join to be kept up to date with these posts. I’m never going to make the A-List, but at least I haz the gimmicks!)
This edition of the weekly (haha) head voices attempts to reflect on the period of time from Monday November 5 to Sunday November 18, 2018.
The following action scene happened exactly halfway through: Pre-requisite running photo, this one taken in Paarl.</description><content:encoded><![CDATA[ <p><em>(Note that there’s now a <a href="https://t.me/headvoices">Telegram group</a> that you can join to be kept up to date with these posts. I’m never going to make the A-List, but at least I haz the gimmicks!)</em></p>
<p>This edition of the weekly (haha) head voices attempts to reflect on the period of time from Monday November 5 to Sunday November 18, 2018.</p>
<p>The following action scene happened exactly halfway through:








<figure><a href="/wp-content/uploads/2018/11/paarl-running-20181111.jpg">
    <img
        
            
            src="/wp-content/uploads/2018/11/paarl-running-20181111-1024x642.jpg"
        
            alt="Pre-requisite running photo, this one taken in Paarl. It was already quite hot. Getting really hot really early in the morning is Paarl’s thing."/> </a><figcaption>
            <p>Pre-requisite running photo, this one taken in Paarl. It was already quite hot. Getting really hot really early in the morning is Paarl’s thing.</p>
        </figcaption>
</figure>
</p>
<h1 id="running-aka-irony-update">Running aka Irony update</h1>
<p>Seeing that you’ve made me talk about running again, have a look at this photo of one Luna Mono 2.0 after about 700 km of (mostly road) running in about seven months, and one brand new Luna Mono 2.0:</p>








<figure><a href="/wp-content/uploads/2018/11/old-vs-new-lunas.jpg">
    <img
        
            
            src="/wp-content/uploads/2018/11/old-vs-new-lunas-1024x768.jpg"
        /> </a>
</figure>

<p>At around about the same time as the new shoes arrived, shortly after South African customs charged me a painful amount before letting the new babies through, both my ankles, from around the posterior tibial tendon area, let me know in no uncertain terms that they were now <em>demanding</em> a break.</p>
<p>After repeated explanations by my life partner (she counts being a rheumatologist amongst her many talents), and by a foot surgeon friend, that my flat feet mean that my posterior tibial tendons have to work even harder than they would usually have done had I been anatomically speaking more normal, I had to start facing the music:</p>
<p><em>I was going to have to wear normal person running shoes again.</em></p>
<p>(If I have to be honest I would have to say that the music was in fact more about having to take a running break. I had sneakily been pushing up my weekly distance, trying to run through ankle discomfort, and this was probably the true core of the problem.</p>
<p>All of that being said, I am choosing to interpret matters a bit differently. Running breaks are really hard yo.)</p>
<p>I’ve now done two runs in my pre-Mono Kinvara 8s, and it does indeed feel (of course it does) like my ankles might slowly be recovering. I am hopeful that the trend continues, and that I can eventually rotate in my Lunas again.</p>
<h1 id="nerd-toys-update-rtx-2070-in-da-house">Nerd toys update: RTX 2070 in da house.</h1>
<p>After weeks of deliberating, I broke down and bought an <a href="https://www.nvidia.com/en-us/geforce/graphics-cards/rtx-2070/">NVIDIA RTX 2070</a> for deep learning.</p>
<p>This in turn led to a flurry of experimentation and to be quite honest a slight case of deep learning binging.</p>
<p>At least I have the following new blog posts to show for it:</p>
<ul>
<li><a href="https://vxlabs.com/2018/11/04/pytorch-1-0-preview-nov-4-2018-packages-with-full-cuda-10-support-for-your-ubuntu-18-04-x86_64-systems/">PyTorch 1.0 preview (Nov 10, 2018) packages with full CUDA 10 support for your Ubuntu 18.04 x86_64 systems</a> – In order to use the shiny new TensorCores on the RTX for more efficient deep learning, you need a CUDA 10 build of PyTorch. YOUR WISH IS MY COMMAND.</li>
<li><a href="https://vxlabs.com/2018/11/19/configuring-emacs-lsp-mode-and-microsofts-visual-studio-code-python-language-server/">Configuring Emacs, lsp-mode and Microsoft’s Visual Studio Code Python language server</a> – When you prefer using Emacs inside of a tmux in a mosh or ssh session to your Linux desktop with the RTX 2070 to develop PyTorch and fastai scripts (no Jupyter in sight, what a relief!), you need the best code-intelligence you can get. Visual Studio Code’s Python Language Server McGuyvered right into Emacs will do nicely thanks!</li>
<li><a href="https://vxlabs.com/2018/11/21/a-simple-ansible-script-to-convert-a-clean-ubuntu-18-04-to-a-cuda-10-pytorch-1-0rc-fastai-miniconda3-deep-learning-machine/">A Simple Ansible script to convert a clean Ubuntu 18.04 to a CUDA 10, PyTorch 1.0rc, fastai, miniconda3 deep learning machine</a> – When you need MOAR firepower to train your networks with larger batch sizes, or just to see how much memory your network would have taken in fp32 mode instead of mixed-precision, this ansible script will reproducibly convert a clean Ubuntu 18.04 GPU instance, such as that supplied by PaperSpace or Google Compute Engine, into a CUDA 10, PyTorch, fastai, miniconda3 deep learning playground, all in about 10 minutes.</li>
</ul>
<p>(I know that some of these occurred outside of the two week timespan covered by this post.)</p>
<h2 id="on-the-memory-saving-of-mixed-precision-training">On the memory saving of mixed-precision training.</h2>
<p>In my tests with ResNet50, a serious convolutional neural network for image classification, the exact same network with the exact same training settings required 14159 MiB in fp32 mode but only 7641 MiB in mixed precision mode.</p>
<p>This means that in some cases, this new RTX 2070 can go toe-to-toe with many far more expensive cards.</p>
<p>Furthermore, I informally measured a training speed boost of about 20% with the smaller ResNet34.</p>
<p>It’s no wonder that the <a href="http://timdettmers.com/2018/11/05/which-gpu-for-deep-learning/">RTX 2070 gets the Tim Dettmers stamp of approval for the most cost-effective training</a>.</p>
<h1 id="your-message-to-take-home">Your message, to take home.</h1>
<p>I came across this backyard philosophy jewel <a href="https://www.reddit.com/r/todayilearned/comments/9ozu4e/til_in_test_screenings_willy_wonka_had_a_scene/">on reddit the other day</a> and loved it. It’s about the 1971 movie W_illy Wonka &amp; the Chocolate Factory_, a stellar adaptation of Roald Dahl’s book <a href="https://en.wikipedia.org/wiki/Charlie_and_the_Chocolate_Factory">Charlie and the Chocolate Factory</a>.</p>
<blockquote>
<p>… in test screenings, Willy Wonka had a scene with a hiker seeking a guru, asking him the meaning of life. The guru requests a Wonka Bar. Finding no golden ticket, he says, “Life is a disappointment.” The director loved it, but few laughed. A psychologist told him that the message was too real.</p>
</blockquote>
<p>Just remember the <a href="/2018/06/03/weekly-head-voices-144-eternal-learner/#the-buddhist-twist">Buddhist Twist</a> my friends:</p>
<blockquote>
<p>… and finally passing through the gate of wishlessness (apranihita) – realizing that nirvana is the state of not even wishing for nirvana.</p>
</blockquote>
]]></content:encoded></item><item><title>Weekly Head Voices #151: We are pleased to meet you.</title><link>https://cpbotha.net/2018/08/08/weekly-head-voices-151-we-are-pleased-to-meet-you/</link><pubDate>Wed, 08 Aug 2018 06:34:27 +0000</pubDate><author>cpbotha@cpbotha.net (Charl P. Botha)</author><guid>https://cpbotha.net/2018/08/08/weekly-head-voices-151-we-are-pleased-to-meet-you/</guid><description> The Weekly Head Voices number 151 are trying to tell you something about the week from Monday July 30 to Sunday August 5.
Prepare yourself for a slightly stranger than usual post. I have: two short programming ideas, a bad review of an outdoor security passive infrared sensor, using Jupyter Notebook for (GPU-accelerated) numerical computation when you only have a browser, computing device input latency, and an utterly unexpected bit of backyard philosophy from the gut.</description><content:encoded><![CDATA[ <p>The Weekly Head Voices number 151 are trying to tell you something about the week from Monday July 30 to Sunday August 5.</p>
<p>Prepare yourself for a slightly stranger than usual post. I have: two short programming ideas, a bad review of an outdoor security passive infrared sensor, using Jupyter Notebook for (GPU-accelerated) numerical computation when you only have a browser, computing device input latency, and an utterly unexpected bit of backyard philosophy from the gut.</p>
<h1 id="two-random-micro-side-project-ideas">Two random micro side-project ideas</h1>
<p>I would like to start with two hobby / maker ideas that popped up in my head this week. There’s a high probability I will not get around to them, but perhaps they help you to spawn a new set of hopefully more worthwhile ideas.</p>
<h2 id="chrome-or-firefox-plugin-to-convert-spotify-playlists-to-apple-music-using-the-new-musickit-js-api">Chrome or Firefox plugin to convert Spotify playlists to Apple Music using the new MusicKit JS API</h2>
<p>I seem to see many more Spotify playlists shared than Apple Music playlists. For example, at this moment I’m listening to the official Lowlands 2018 playlist.</p>
<p>This is not ideal, as I am an Apple Music subscriber, but not a Spotify subscriber.</p>
<p>It turns out there are paid apps to convert Spotify playlists to Apple music playlists.</p>
<p>However, it also turns out that Apple has a new thing (still in beta) called <a href="https://developer.apple.com/documentation/musickitjs">MusicKit JS</a>.</p>
<p>I briefly dissected the Spotify Playlist website.</p>
<p>It would be straight-forward for a Chrome or Firefox plugin (WebExtension, so same code. I’ve done this before) to go through this playlist, search for each track using the MusicKit JS API, and then recreate the playlist in the user’s Apple Music account.</p>
<p>This solution would be much cleaner and simpler than the current app-based ones.</p>
<h2 id="an-emacs-package-for-displaying-your-rescuetime-productivity-metric-right-on-the-mode-line">An Emacs package for displaying your RescueTime productivity metric right on the mode line</h2>
<p>I scanned the <a href="https://www.rescuetime.com/apidoc">RescueTime API documentation</a>.</p>
<p>I was just about to start working on it, when I came up with the bright idea to name the package ironic.el, and so I stopped.</p>
<p>On that topic: The struggle for practically sustainable focus is real, and it never seems to stop.</p>
<h1 id="the-head-voices-reviewtm-the-optex-hx-80-outdoor-passive-infrared-security-detector-avoid-at-all-costs">The Head Voices REVIEW(tm) the Optex HX-80 outdoor passive infrared security detector: AVOID AT ALL COSTS</h1>
<p>From the <a href="https://www.optexamerica.com/security-products/hx-80n">Optex HX-80 outdoor passive infrared security detector’s web-page</a> we have the following:</p>
<blockquote>
<p><strong>The most important element in reliable outdoor detector is accuracy to distinguish a human from a small animal</strong>. … In addition, the HX-80N’s dual PIR’s and 20 detection zones utilize the ‘AND’ detection pattern technology … <strong>This technology helps to prevent false alarms caused by a pet or small animal.</strong></p>
</blockquote>
<p>Well, I had two of these installed by trained professionals.</p>
<p>(There are of course interesting discussions to be had about the necessity of devices such as the HX-80, or its mythical actually working counterpart, down here.)</p>
<p>I can confirm that they excel at one fairly specific function: Triggering the alarm, and thus automatically calling my security company, at the most ungodly hours of the night, whenever a certain small grey cat, looking exceptionally unlike a human, decides to take a stroll outside of our house.</p>
<div class="jetpack-video-wrapper">
<span class="embed-youtube" style="text-align:center; display: block;"><iframe allowfullscreen="true" class="youtube-player" height="473" src="https://www.youtube.com/embed/8ZXAmMroePI?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" style="border:0;" type="text/html" width="840"></iframe></span>
</div>
<p>Oh yes, the cat is not even ours, but belongs to our neighbour.</p>
<p>The installation and subsequent repeated fine-tuning of our Optex HX-80 have only had the result of me having to punch in an additional key-sequence every evening to bypass the two ‘AND’-detection-pattern-technology-equipped HX-80 devices.</p>
<p>You will understand that the only reasonable Head Voices REVIEW(tm) of the Optex HX-80 is:</p>
<ul>
<li>100% NON-FUNCTIONING THROUGH INFERIOR DESIGN.</li>
<li>AVOID AT ALL COSTS.</li>
<li>DON’T TRUST THE MARKETING.</li>
<li>THE TRUTH IS OUT THERE.</li>
<li>JUST DON’T.</li>
</ul>
<p><img src="data:image/jpeg;base64,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" alt="Image result for just don&rsquo;t meme"></p>
<h1 id="some-more-odd-but-perhaps-useful-bits">Some more odd but perhaps useful bits</h1>
<h2 id="google-colaboratory-for-numerical-computation-when-all-you-have-is-a-browser">Google Colaboratory for Numerical Computation when all you have is a browser.</h2>
<p>I’m late to the party (again), but <a href="https://colab.research.google.com/notebooks/welcome.ipynb">Google Colab</a> is really great if you need a Jupyter Notebook with some GPU power behind it.</p>
<p>It comes with tensorflow pre-installed (being Google and all), but getting the GPU-accelerated PyTorch 0.4.1 (latest version of the most amazing deep learning tool at the time of writing) going was a cinch.</p>








<figure><a href="/wp-content/uploads/2018/08/google_colab_torch_0.4.1.png">
    <img
        
            
            src="/wp-content/uploads/2018/08/google_colab_torch_0.4.1.png"
        /> </a>
</figure>

<p>To repeat this experiment, create new notebook with File | New Python 3 Notebook, then change Edit | Notebook Settings | Hardware accelerator to GPU.</p>
<p>You can then install the correct version of PyTorch by executing</p>
<pre>!pip install http://download.pytorch.org/whl/cu80/torch-0.4.1-cp36-cp36m-linux_x86_64.whl</pre>
<p>in a notebook cell.</p>
<p>What a time to be alive!</p>
<p>P.S. Remember, <a href="/2018/07/17/weekly-head-voices-148-data-stylist/#development-environment-pycharm">under normal (non-Colab) circumstances</a> we keep our Notebooks as empty as possible. Prefer as much as possible of your code in Python modules. The notebooks are only there to act as glue, for visualization and sometimes for long-running jobs.</p>
<h2 id="dan-luus-computer-and-mobile-device-input-latency-research">Dan Luu’s computer and mobile device input latency research</h2>
<p><a href="https://danluu.com/input-lag/">This most amazing work</a> was recently brought to my attention by WHV reader <a href="https://matthewbrecher.com/">Matthew Brecher</a> in the comments under my <a href="/2017/02/12/android-vs-iphone-performance-a-quick-note/">2017 Android vs iPhone performance post</a>.</p>
<p>In it, Dan Luu measured the input latency of various devices, using the 240fps camera on his iPhone SE, or with the 1000 fps  Sony RX100 V camera if the device was too fast.</p>
<p>For the computers in his study, input latency was defined as the time between keypress and character appearing on the display. For the mobile devices, it was defined as the time between finger movement and display scrolling starting.</p>
<p>If you have any interest in this sort of technology and also in-depth technology journalism, <a href="https://danluu.com/input-lag/">the full article</a> is definitely worth your time.</p>
<p>I wanted to mention two interesting points:</p>
<ol>
<li>The 1983 Apple 2e, with a CPU running at 1MHz, had significantly lower input latency (30ms between button press and character display) than any modern multi-GHz system. The comparison is of course not completely fair, but it’s still nice to see.</li>
<li>Amongst the mobile devices, Apple dominates the fast / low latency end of the spectrum. Their devices, in terms of input lag, are ALL faster than all of the Android devices tested, including for example the 2017 Google Pixel 2XL.
<ul>
<li>Yes, this is me eating my hat, and some more of that yummy humble pie.</li>
<li>Android 9, code-name Pie, has just been (will soon be… err) released and has an <a href="https://www.theguardian.com/technology/2018/aug/07/android-9-pie-google-new-mobile-os-everything-you-need-to-know">amazing list of features</a>. I still hope they manage they also manage to catch up with regards to some of the basics like input latency.</li>
</ul>
</li>
</ol>
<h2 id="yet-another-reason-to-eat-more-fibre">Yet another reason to eat more fibre</h2>
<p>There are an <a href="https://en.wikipedia.org/wiki/Human_microbiota">estimated 100 trillion (10 to the power of 14; 100 with 12 zeroes) bacterial cells</a> housed in each of our bodies.</p>
<p>Each adult human consists of on average only 37 trillion human cells, meaning there are on average almost 3 alien cells for every 1 of your own cells.</p>
<p>I find this a beautiful realisation: All aspects of our lives depend on this multitude of foreign visitors.</p>
<p>They help us digest our food, and, as it has been turning out more recently, they play a crucial role in our mood,  our behaviour and our thinking.</p>
<p>We (or at least the clever people) now talk about the <a href="https://en.wikipedia.org/wiki/Gut%E2%80%93brain_axis">microbiome-gut-brain axis</a>, further underlining the importance that our bacterial visitors play in our lives.</p>
<p>Taking a few more steps back, thinking about the relationship between the 37 trillion human cells, and the 100 trillion visiting cells,  I ask the question:</p>
<p>Who am I really? Who exactly is thinking this?</p>
<p>I, or perhaps rather “we”, find this truly fascinating.</p>
<p>What I was initially planning to mention before going off on this tangent, was a recent paper accepted for publication in the Journal of Physiology, with the title Short-Chain Fatty Acids: <a href="https://physoc.onlinelibrary.wiley.com/doi/epdf/10.1113/JP276431">Microbial Metabolites That Alleviate Stress-induced Brain-Gut Axis Alterations (click for PDF fulltext)</a>.</p>
<p>The Physiological Society press release is more digestibly (I had to) titled “<a href="http://www.physoc.org/press-release/2018/eat-high-fibre-foods-reduce-effects-stress-gut-and-behaviour">Eat high fibre foods to reduce effects of stress on gut and behaviour</a>“.</p>
<p>In short, fibre stimulates gut bacteria to produce short-chain fatty acids (SCFA), which, besides being the main source of nutrition for cells in this region of the body, also decrease levels of stress and anxiety, at the very least in mice.</p>
<h1 id="the-end">The end</h1>
<p>Thank you for sticking around friends!</p>
<p>I hope that you found something of value, even if not directly from this post.</p>
<p>I’ll see you next time! Until then, remember to eat your vegetables.</p>
]]></content:encoded></item><item><title>Weekly Head Voices #150: The Road not Taken.</title><link>https://cpbotha.net/2018/07/31/weekly-head-voices-150-the-road-not-taken/</link><pubDate>Tue, 31 Jul 2018 20:40:21 +0000</pubDate><author>cpbotha@cpbotha.net (Charl P. Botha)</author><guid>https://cpbotha.net/2018/07/31/weekly-head-voices-150-the-road-not-taken/</guid><description> Photo of a cotula lineariloba flower, taken by GOU#1, age 12.
This edition of the WHV covers the week from Monday, July 23 up to and including Sunday, July 29.
Running update Strava says I’ve just passed the 300km threshold in my Luna Mono 2 sandals.
It also says I’ve done 27km in my Xero Genesis sandals, or as I have begun to call them, Xero Tolerance.</description><content:encoded><![CDATA[ 







<figure><a href="/wp-content/uploads/2018/07/IMG_2740.jpg">
    <img
        
            
            src="/wp-content/uploads/2018/07/IMG_2740-768x1024.jpg"
        
            alt="Photo of a cotula lineariloba flower, taken by GOU#1, age 12."/> </a><figcaption>
            <p>Photo of a cotula lineariloba flower, taken by GOU#1, age 12.</p>
        </figcaption>
</figure>

<p>This edition of the WHV covers the week from Monday, July 23 up to and including Sunday, July 29.</p>
<h1 id="running-update">Running update</h1>
<p>Strava says I’ve just passed the 300km threshold in my <a href="/2018/04/08/weekly-head-voices-139-luna/">Luna Mono 2 sandals</a>.</p>
<p>It also says I’ve done 27km in my <a href="/2018/07/17/weekly-head-voices-148-data-stylist/#weekend-running-update">Xero Genesis sandals</a>, or as I have begun to call them, <em>Xero Tolerance</em>.</p>
<p>You make one mistake, and something will break. You do get to keep all the bloody pieces.</p>
<p>In any case, when I started on this barefoot-style / natural running adventure, I had subconsciously set myself the limit of 200km before evaluating the success of the experiment.</p>
<p>At 200km, the experiment was still unsuccessful (different parts of feet and ankles were taking turns complaining) so I moved the threshold to 300km, with the plan to move it to 400km if required.</p>
<p>I call this The Stubborn Scientific Method(tm): You keep <em>running</em> the experiment (harr harr) until it says what you want it to say.</p>
<p>To be fair, in this specific case an injury would have (and still can), stop the experiment. Most fortunately the muscles, bones and tendons in my feet, ankles and calves, although complaining quite audibly, have held up.</p>
<p>This past Sunday I did a long(ish) run where it felt for the first time like my feet and ankles had finally toughened up enough (and perhaps my form had also improved slightly) to just keep on propelling me forward quietly and efficiently.</p>
<p>Together with the brilliant sunny winter morning conditions, this conspired to reconfigure my face machine into a rather long-lasting grin.</p>
<p>I am carefully optimistic that I might be able to make this specific adventure a more permanent one, and that makes me really happy.</p>
<h1 id="the-emacs-section">The Emacs Section</h1>
<p><em>NERD-ALERT. SKIP TO THE NEXT SECTION IF YOU ARE NOT INTO TEXT EDITORS!</em></p>
<p>A friend from work sent me a ZIP file with research data.</p>
<p>I was super surprised that I could easily decompress the ZIP file using Emacs Dired (Dired is of course the file-manager built into Emacs, doh), but that there was no easy way to mark and extract specific files from the archive.</p>
<p>I found <a href="https://emacs.stackexchange.com/a/3843/8743">an SO answer with a piece of Emacs Lisp code</a> that someone had put together and integrated it with my Emacs.</p>
<p>It worked, but it didn’t default to the opposite Dired file-list pane as all commander-style tools should do, and by default it re-created relative paths, which is the opposite of the default in most two-pane commanders I know.</p>
<p>As is the wont of Emacs users, I reshaped the code ever so slightly to work like I thought it should.</p>
<p>Shaping Emacs Lisp code has a pleasant fluid feeling to it. Code is data, code is configuration, data flows through code.</p>
<p>I’m telling you this story, because it was a nice little reminder of one of the reasons I like this software so much.</p>
<p>You can find <a href="https://gist.github.com/cpbotha/05e07dee7fd8243ba73339be186c0b88">my modified version of archive-extract-to-file.el as a github gist</a>.</p>
<h1 id="the-odd-bits-of-interesting-news-section">The Odd Bits of Interesting News Section</h1>








<figure><a href="/wp-content/uploads/2018/07/Screen-Shot-2018-07-31-at-22.22.59.png">
    <img
        
            
            src="/wp-content/uploads/2018/07/Screen-Shot-2018-07-31-at-22.22.59-1024x509.png"
        /> </a>
</figure>

<ul>
<li><a href="https://distill.pub/2018/differentiable-parameterizations/">Differentiable Image Parameterizations</a>, a beautiful machine learning article on Distill that surveys and showcases different techniques for generating beautiful images with deep learning. These networks sort of learn to see in order to solve specific tasks, but you can tickle them in different ways to get them to show you the insides of their visual circuitry, and it’s quite beautiful.</li>
<li><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1963310/#__ffn_sectitle">The Prophylactic Extraction of Third Molars: A Public Health Hazard</a> is an article which was published all the way back in 2007. It makes the claim that at least two thirds of wisdom tooth extraction are unnecessary. One could say that their only function is to… <em>extract</em> your money. BA DUM TSSSSS! To that I would like to add: WHY DENTISTRY WHY? HAVE YOU NOT HURT US ENOUGH?!</li>
<li>A colleague at work emailed <a href="https://techcrunch.com/2018/07/26/this-3d-printed-ai-construct-analyzes-by-bending-light/">this TechCrunch post about a 3D printed neural network</a> that diffracts light going through in order to do its trained inference work on incoming images. Although it’s a retro-futuro-mind-bending idea to do it with a whole neural network, and it smacks of hell-yeah-this-is-what-scifi-promised-me-that-AI-would-look-like, I could not help but recall a certain Very Flat Cat telling us about this sort of passive light-based computation almost 20 years ago.</li>
</ul>
<h1 id="the-poetry-section">The Poetry Section</h1>
<p>GOU#1 had to select an English poem to recite for class.</p>
<p>From the depths of my memory bubbled up <a href="https://www.poetryfoundation.org/poems/44272/the-road-not-taken">The Road not Taken by Robert Frost</a>.</p>
<p>I had forgotten how much subtlety and recognisable human complexity this poem was able to pack into such a petite little frame. If you have the time, read the analysis linked above after spending some time with the poem itself.</p>
<blockquote>
<p>Two roads diverged in a yellow wood,</p>
</blockquote>
<blockquote>
<p>And sorry I could not travel both</p>
</blockquote>
<blockquote>
<p>And be one traveler, long I stood</p>
</blockquote>
<blockquote>
<p>And looked down one as far as I could</p>
</blockquote>
<blockquote>
<p>To where it bent in the undergrowth;</p>
<p>Then took the other, as just as fair,</p>
</blockquote>
<blockquote>
<p>And having perhaps the better claim,</p>
</blockquote>
<blockquote>
<p>Because it was grassy and wanted wear;</p>
</blockquote>
<blockquote>
<p>Though as for that the passing there</p>
</blockquote>
<blockquote>
<p>Had worn them really about the same,</p>
<p>And both that morning equally lay</p>
</blockquote>
<blockquote>
<p>In leaves no step had trodden black.</p>
</blockquote>
<blockquote>
<p>Oh, I kept the first for another day!</p>
</blockquote>
<blockquote>
<p>Yet knowing how way leads on to way,</p>
</blockquote>
<blockquote>
<p>I doubted if I should ever come back.</p>
<p>I shall be telling this with a sigh</p>
</blockquote>
<blockquote>
<p>Somewhere ages and ages hence:</p>
</blockquote>
<blockquote>
<p>Two roads diverged in a wood, and I—</p>
</blockquote>
<blockquote>
<p>I took the one less traveled by,</p>
</blockquote>
<blockquote>
<p>And that has made all the difference.</p>
</blockquote>
<p>Friends, no matter which paths you take this week, I hope that we may meet again.</p>
]]></content:encoded></item><item><title>Weekly Head Voices #149: I forgot to proof-read this.</title><link>https://cpbotha.net/2018/07/24/weekly-head-voices-149/</link><pubDate>Tue, 24 Jul 2018 20:49:20 +0000</pubDate><author>cpbotha@cpbotha.net (Charl P. Botha)</author><guid>https://cpbotha.net/2018/07/24/weekly-head-voices-149/</guid><description> Part of the Sunday morning trail. Although I really enjoy these, I’m at my happiest running down antelope on the savannah. Antelope strictly-speaking not required, but those wide open plains on the other hand…
This, the one hundred and forty ninth edition of the Weekly Head Voices, covers the week from Monday July 16 to Sunday July 22 of the year 2018.
This week, we have apple watch running adventures, deep learning in production (finally), yet another focus tip and finally a youtube poetry reading.</description><content:encoded><![CDATA[ 







<figure><a href="/wp-content/uploads/2018/07/IMG_0420-PANO.jpg">
    <img
        
            
            src="/wp-content/uploads/2018/07/IMG_0420-PANO-1024x318.jpg"
        
            alt="Part of the Sunday morning trail. Although I really enjoy these, I’m at my happiest running down antelope on the savannah.  Antelope strictly-speaking not required, but those wide open plains on the other hand…"/> </a><figcaption>
            <p>Part of the Sunday morning trail. Although I really enjoy these, I’m at my happiest running down antelope on the savannah.  Antelope strictly-speaking not required, but those wide open plains on the other hand…</p>
        </figcaption>
</figure>

<p>This, the one hundred and forty ninth edition of the Weekly Head Voices, covers the week from Monday July 16 to Sunday July 22 of the year 2018.</p>
<p>This week, we have apple watch running adventures, deep learning in production (finally), yet another focus tip and finally a youtube poetry reading.</p>
<p>Enjoy!</p>
<h1 id="the-apple-watch-vitality-and-you">The Apple Watch, Vitality and You</h1>
<p>On Monday, I became the owner of a brand new Apple Watch 3, FOR FREE(ish).</p>
<p>I feel that two points are worth mentioning:</p>
<ol>
<li>Having one’s work macbook unlock <em>automatically</em> as one prepares to put one’s hands on the keyboard, with a sweet little unlock sound emitting from one’s watch, is much more fun than I had expected.
<ul>
<li>Said watch has a <a href="https://en.wikipedia.org/wiki/Apple_S3">dual-core processor with 768MB of RAM and 16GB of flash, and a GPU</a>. That’s just crazy.
<ul>
<li>In 2003, <a href="/2003/10/05/first-thoughts-on-the-tungsten-e/">I had similar thoughts about the processing power of my Tungsten E PDA</a>, and all the way back in <a href="/2016/12/06/weekly-head-voices-113-science-and-creation/#devil-on-my-arm">2016 I was already laughing at 2003 me</a>. I should know better by now.</li>
</ul>
</li>
</ul>
</li>
<li>One was looking forward to using third party running apps on the watch, such as iSmoothRun which does real-time reporting of cadence, which can be shown together with a number of other stats on a number of configurable screens a la Garmin . One has had to cancel these plans, because Vitality, the shadowy organisation responsible for the FOR FREE(ish) nature of the watch, only recognises runs submitted by the built-in Workouts app.
<ul>
<li>The September watchOS update will include runtime (haha) cadence, which is great. However, some technical system for the support of third party apps would have been even better. I’ll live.</li>
<li>Runs logged with the built-in Workouts app can be easily and automatically submitted to other platforms, such as Strava, where many of my running peeps hang out, and even to one’s own Dropbox in FIT format, with <a href="https://itunes.apple.com/za/app/healthfit/id1202650514?mt=8">the HealthFit iOS app</a>, a very reasonable once-off purchase.</li>
</ul>
</li>
</ol>
<h1 id="deeplearning-insidetm">DeepLearning Inside(tm)</h1>
<p>On Friday, we shipped a new version of the most important work project I am currently involved in.</p>
<p>Again I feel that two points are worth mentioning:</p>
<ol>
<li>We now also have deep learning, albeit a humble example, out in actual production. I was starting to feel a little left out. Anonymous shout-out (because top secret) to the team members who made this happen!</li>
<li>They say one should never deploy or ship on Friday. Because I come from the I-won’t-do-what-you-tell-me generation, I cut the final release on Friday evening <em>after</em> the traditional weekend-starter braai.
<ul>
<li>To be honest, this was only <em>necessary</em> because I had promised our client that we would release, and it was only <em>possible</em> because we have a fairly good test-suite, with end-to-end being most crucial in this specific scenario, and a checklist-style release procedure.</li>
</ul>
</li>
</ol>
<h1 id="sobsodsit-cipwob-fba">SoBSoDSiT-CIPWOB-FBA</h1>
<p>As part of my chaotic but ever-evolving constellation of systems for maintaining work focus, I have renamed the <a href="/2018/05/20/weekly-head-voices-143-the-rider-and-the-elephant/#shorter-focus-blocks-work-better">shorter focus blocks approach</a> to the <em>short-but-specially-defined-so-that-completion-is-possible-within-one-block focus blocks approach</em> (SBSDSTCIPWOB-FBA).</p>
<p>This adds the incentive of a small but probable shot of dopamine at the end of the focus block, and sometimes even leads to its unwitting extension by the woefully undersized (not to mention super lazy) rider sometimes sitting atop my mental elephant.</p>
<p>It sometimes feels like I’m slowly reinventing GTD.</p>
<p>(This blog post is an emotional roller coaster ride for me. This is the first time I’m feeling something.)</p>
<p><a href="/2007/10/07/my-palmos-based-gtd-setup/">I used to be a fan of GTD</a> when I still believed that my function in life was to answer emails really quickly, and master multi-tasking.</p>
<p>Since then however, I’ve slowly had to come to the realisation that, at least in my case, the amount of email processed is more or less exactly inversely correlated to the actual value that I produce.</p>
<h1 id="the-impotence-of-proof-reading">The impotence of proof-reading</h1>
<p>The following poetry reading made various subsets of my neurons fire in extremely pleasant ways.</p>
<p>I hope that you experience similar effects. See you next time!</p>
<div class="jetpack-video-wrapper">
<span class="embed-youtube" style="text-align:center; display: block;"><iframe allowfullscreen="true" class="youtube-player" height="473" src="https://www.youtube.com/embed/OonDPGwAyfQ?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" style="border:0;" type="text/html" width="840"></iframe></span>
</div>
]]></content:encoded></item><item><title>Weekly Head Voices #118: Accelerando.</title><link>https://cpbotha.net/2017/03/10/weekly-head-voices-118-accelerando/</link><pubDate>Fri, 10 Mar 2017 21:14:38 +0000</pubDate><author>cpbotha@cpbotha.net (Charl P. Botha)</author><guid>https://cpbotha.net/2017/03/10/weekly-head-voices-118-accelerando/</guid><description> Too much nerdery took place from Monday February 20 to Sunday March 5. Fortunately, be the end of that period, we found ourselves here: The view from the shark lookout all the way to Hangklip.
bibtex references in orgmode For a technical report, I thought it would be handy going from Emacs orgmode (where all my lab notes live in any case) to PDF via LaTeX.
This transformation is more or less built-in, but getting the whole machinery to work with citations from a local BibTeX export from my main Zotero database does not work out of the box.</description><content:encoded><![CDATA[ <p>Too much nerdery took place from Monday February 20 to Sunday March 5. Fortunately, be the end of that period, we found ourselves here:








<figure><a href="/wp-content/uploads/2017/03/looking_at_hangklip.jpg">
    <img
        
            
            src="/wp-content/uploads/2017/03/looking_at_hangklip-1024x540.jpg"
        
            alt="The view from the shark lookout all the way to Hangklip."/> </a><figcaption>
            <p>The view from the shark lookout all the way to Hangklip.</p>
        </figcaption>
</figure>
</p>
<h1 id="bibtex-references-in-orgmode">bibtex references in orgmode</h1>
<p>For a technical report, I thought it would be handy going from Emacs orgmode (where all my lab notes live in any case) to PDF via LaTeX.</p>
<p>This transformation is more or less built-in, but getting the whole machinery to work with citations from a local BibTeX export from my main Zotero database does not work out of the box.</p>
<p>I wrote <a href="https://vxlabs.com/2017/02/20/from-org-file-with-local-bibtex-to-latex-and-pdf/">a post on my other even-more-nerdy blog</a> showing the extra steps needed to turn this into an easy-peasy 38-shortcut-key-combo affair.</p>
<h1 id="google-gce-k80-cpus-available-cheapish">Google GCE K80 CPUs available, cheap(ish)!</h1>
<p>I’ve been using a cloud-hosted NVIDIA Tesla from Nimbix for my small-scale deep learning experiments with TensorFlow. This has also helped me to resist the temptation of buying an expensive new GPU for my workstation.</p>
<p>However, Google <a href="https://cloud.google.com/compute/docs/gpus/">Compute Engine has finally shipped (in beta) their cloud-based GPU product</a>. Using <a href="https://cloud.google.com/products/calculator/">their pricing calculator</a>, it turns out I can get a virtual machine with 8 CPU cores, 30G of RAM, 375GB of local SSD and a whole NVIDIA Tesla K80 GPU (12GB of memory) in their EU data centre for a paltry $1.32 / hour.</p>
<p>This is significantly less than half of what I paid Nimbix!</p>
<p>(That resistance is going to crumble, the question is just when. Having your stuff run locally and interactively for small experiments still beats the 150ms latency from this here tip of the African continent to the EU.)</p>
<h1 id="nvpy-leaves-the-nest-">nvpy leaves the nest :`(</h1>
<p>My most successful open source project to date is probably <a href="https://github.com/cpbotha/nvpy">nvpy</a>, the cross-platform (Linux, macOS, Windows) Simplenote client. 600+ stars on github is not A-list, but it’s definitely also nothing to sneeze at.








<figure><a href="/wp-content/uploads/2017/03/20170304-nvpy-github-stats-before-xfer.png">
    <img
        
            
            src="/wp-content/uploads/2017/03/20170304-nvpy-github-stats-before-xfer.png"
        
            alt="nvpy stats right before the hand-over"/> </a><figcaption>
            <p>nvpy stats right before the hand-over</p>
        </figcaption>
</figure>
</p>
<p>Anyways, I wrote nvpy in 2012 when I was still a heavy Simplenote user and there was no good client for Linux.</p>
<p>In the meantime, Emacs had started taking over my note-taking life and so in October of 2014, I made the decision to <a href="https://groups.google.com/forum/#!msg/nvpy/_GuWNfnxY9E/S0Vel4i4MEgJ">start looking for a new maintainer</a> for my open-source baby nvpy.</p>
<p>That attempt was not successful.</p>
<p>By the end of 2015 / early 2016 I had a bit of a Simplenote / nvpy revival, as <a href="/2016/01/05/note-taking-strategy-early-2016/">I was using the official client on my phone, and hence nvpy on the desktop</a>.</p>
<p>Emacs put a stop to that revival also by magically becoming available on my phone as well. I have to add that the Android Simplenote client also seems to have become quite sluggish.</p>
<p>I really was not using nvpy anymore, but I had to make plans for the users who did.</p>
<p>On Saturday March 4, I approached github user <a href="https://github.com/yuuki0xff">yuuki0xff</a>, who had prepared a pretty impressive background-syncing PR for nvpy, about the possibility of becoming the new owner and maintainer of nvpy.</p>
<p>To my pleasant surprise, he was happy to do so!</p>
<p>It is a strange new world that we live in where you create a useful artifact from scratch, make it available for free to anyone that would like to use it, and continue working on improving that artifact for a few years, only to hand the whole thing over to someone else for caretaking.</p>
<p>The handing-over brought with it mixed feelings, but overall I am super happy that my little creation is now in capable and more active hands.</p>
<h1 id="navel-gaze">Navel Gaze</h1>
<p>Fortunately, there’s a <em>handy</em> twitter account reminding us regularly how much of 2017 we have already put behind us (thanks <a href="https://twitter.com/gvrooyen">G-J van Rooyen</a> for the tip):</p>
<blockquote class="twitter-tweet" data-width="550">
<p dir="ltr" lang="und">
    ▓▓▓░░░░░░░░░░░░ 17%
  </p>
<p>
    — Year Progress (@year_progress) <a href="https://twitter.com/year_progress/status/837845049257902080">March 4, 2017</a>
</p>
</blockquote>
<p>That slowly advancing progress bar seems to be very effective at getting me to take stock of the year so far.</p>
<p>Am I spending time on the right things? Am I spending just the right amount of effort on prioritising without this cogitation eating into the very resource it’s supposed to be optimising? Are my hobbies optimal?</p>
<p>I think the answer is: One deliberate step after the other is best.</p>
]]></content:encoded></item></channel></rss>