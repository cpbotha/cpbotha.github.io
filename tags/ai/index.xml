<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AI on voices in my head</title><link>https://cpbotha.net/tags/ai/</link><description>Recent content in AI on voices in my head</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><managingEditor>cpbotha@cpbotha.net (Charl P. Botha)</managingEditor><webMaster>cpbotha@cpbotha.net (Charl P. Botha)</webMaster><lastBuildDate>Sun, 29 Nov 2020 09:50:00 +0200</lastBuildDate><atom:link href="https://cpbotha.net/tags/ai/index.xml" rel="self" type="application/rss+xml"/><item><title>Weekly Head Voices #210: MiniBurn 2020</title><link>https://cpbotha.net/2020/11/29/weekly-head-voices-210-miniburn-2020/</link><pubDate>Sun, 29 Nov 2020 09:50:00 +0200</pubDate><author>cpbotha@cpbotha.net (Charl P. Botha)</author><guid>https://cpbotha.net/2020/11/29/weekly-head-voices-210-miniburn-2020/</guid><description> Welcome back to the WHV blogging clubhouse, gang!
Somewhat inspired by Descartes, I can say with a fair amount of confidence that you are now reading these words, and for that I am grateful.
This post covers the weeks from Monday, November 9 to Sunday, November 22 of the year 2020.
papercite_static: put some bibtex into your Hugo After languishing for almost a year on my todo list, I finally got around to cleaning up and making available my Python script for embedding your BiBTeX bibliographies in your markdown files.</description><content:encoded><![CDATA[ 







<figure><a href="dirt_road_to_stanford.jpg">
    <img
        
            sizes="(min-width: 35em) 1200px, 100vw"
              
            srcset='
            
                   https://cpbotha.net/2020/11/29/weekly-head-voices-210-miniburn-2020/dirt_road_to_stanford_hu0d74330c058446a99ca5dd87a0591421_1983338_480x0_resize_q75_box.jpg 480w,
            
                   https://cpbotha.net/2020/11/29/weekly-head-voices-210-miniburn-2020/dirt_road_to_stanford_hu0d74330c058446a99ca5dd87a0591421_1983338_800x0_resize_q75_box.jpg 800w,
            
                   https://cpbotha.net/2020/11/29/weekly-head-voices-210-miniburn-2020/dirt_road_to_stanford_hu0d74330c058446a99ca5dd87a0591421_1983338_1200x0_resize_q75_box.jpg 1200w,
            
                   https://cpbotha.net/2020/11/29/weekly-head-voices-210-miniburn-2020/dirt_road_to_stanford_hu0d74330c058446a99ca5dd87a0591421_1983338_1500x0_resize_q75_box.jpg 1500w,
            '

            
            
            src="https://cpbotha.net/2020/11/29/weekly-head-voices-210-miniburn-2020/dirt_road_to_stanford_hu0d74330c058446a99ca5dd87a0591421_1983338_800x0_resize_q75_box.jpg"
            

        /> </a>
</figure>

<p>Welcome back to the WHV blogging clubhouse, gang!</p>
<p>Somewhat inspired by Descartes, I can say with a fair amount of confidence that
you are now reading these words, and for that I am grateful.</p>
<p>This post covers the weeks from Monday, November 9 to Sunday, November 22 of
the year 2020.</p>
<h2 id="papercite-static-put-some-bibtex-into-your-hugo">papercite_static: put some bibtex into your Hugo</h2>
<p>After languishing for almost a year on my todo list, I finally got around to
cleaning up and making available my Python script for embedding your BiBTeX
bibliographies in your markdown files.</p>
<p>The script is called <a href="https://github.com/cpbotha/papercite%5Fstatic">papercite_static</a>, because it was inspired by <a href="https://wordpress.org/plugins/papercite/">the papercite
Wordpress plugin</a> that I previously used, but it was built for use in static
websites.</p>
<p>Catchy right?</p>
<p>This is pretty useful when you are academically inclined, or just really like
managing BiBTeX files.</p>
<p>If you&rsquo;re one of those people, you can go check it out at <a href="https://github.com/cpbotha/papercite%5Fstatic">the papercite_static
github page</a>.</p>
<h2 id="save-image-from-clipboard">save_image_from_clipboard</h2>
<p>From the Department of Catchy Names, the same one that brought you the script
above, comes <a href="https://github.com/cpbotha/save%5Fimage%5Ffrom%5Fclipboard">save_image_from_clipboard</a>!</p>
<p>I wrote this to scratch my own extremely niche itch (scranitch-ware!), but it
could be useful in other slightly less niche contexts.</p>
<p>My Emacs is configured with the org-download package so that I can use any
system tool to screenshot an arbitrary region of my screen to the clipboard,
and then tell Emacs to attach whatever is in the clipboard to the current
Orgmode heading.</p>
<p>This is something I use really often during daily note-taking and task
management.</p>
<p>The org-download package expects a PNG image to be available on the
clipboard. When this is not the case, because the screenshotting or other image
copying workflow instead copied a JPG or a BMP (long story, starts with a W,
ends with SL&hellip;), I get a blank attachment which makes me sad, and costs me
more time.</p>
<p>On macOS, I used <a href="https://github.com/jcsalterego/pngpaste">pngpaste</a> for this, a tool that ensures that whatever image
format is in the clipboard gets converted to PNG.</p>
<p>Well, <a href="https://github.com/cpbotha/save%5Fimage%5Ffrom%5Fclipboard">save_image_from_clipboard</a> does exactly this, and a little more by simply
converting whatever&rsquo;s on the clipboard to the format that you specify.</p>
<p>This has already saved me countless SECONDS of time, and a substantial amount
of frustration.</p>
<p>P.S. I&rsquo;ve again been spending more hobby time with <a href="https://nim-lang.org/">nim</a>, which would have
resulted in a much smaller and faster binary in this case, but the Python
version wrote itself fairly quickly, with both of my hands behind my back.</p>
<p>P.P.S. nim is <em>so</em> hard to resist, in spite of what <a href="/2019/04/15/weekly-head-voices-169-a-cunning-plan/#nimfatuation-is-now-over">I wrote about nimfatuation
being over, back in WHV #169</a>. It combines much of the expressiveness and some
of the batteries-included of Python, paired with the generation of tiny
self-contained binaries.</p>
<h2 id="my-emacs-is-now-all-in-on-ivy">My Emacs is now all-in on Ivy</h2>
<p>As you will <em>most probably</em> remember from <a href="/2019/05/22/weekly-head-voices-171-icemirb/#you-can-easily-dired-jump-to-the-currently-ivy-readd-file-in-emacs">WHV #171</a>, my Emacs configuration used
a mishmash of <a href="https://github.com/emacs-helm/helm">Helm</a> and <a href="https://github.com/abo-abo/swiper">Ivy</a>.</p>
<p>Helm and Ivy are two great, but different, examples of Emacs completion /
selection frameworks, something that is really important to any disciple of
this amazing religion.</p>
<p>In something that is probably some sort of reflection of my character, I was
happily using both of them simultaneously for quite a while.</p>
<p>However, waking up one morning with the realisation that this was yet another
small context switch that was costing me time and focus, in one of my highest
ROI tool workflows to boot, I decided that it was time to excise Helm from my
configuration.</p>
<p>Fast-forward a few hours of Lisp-driven terraforming, and I was all-in on my
Ivy.</p>
<p>During this terraforming I ran into some undesired behaviour in ivy-rich, which
resulted first in me writing <a href="https://vxlabs.com/2020/11/15/fix-ivy-rich-switch-buffer-directories-display-in-emacs/">a blog post documenting the work-around</a>, then
noticing that ivy-rich&rsquo;s astute author had subsequently integrated part of my
fix, and finally authoring a <a href="https://github.com/Yevgnen/ivy-rich/pull/92">github pull request (PR)</a>, merged shortly after to
fix the remaining issues.</p>
<p>P.S. I sometimes wonder whether people outside of the open source world
understand how much github contributed to the software world by streamlining
the process whereby random developers are able to contribute lines of source
code into open source projects like this.</p>
<p>WELL DO YA?!</p>
<h2 id="mynoise-dot-net-is-an-amazing-soundscape-generator">mynoise.net is an amazing soundscape generator</h2>
<p>In the past few weeks, Lazar Focus has rescued my days so often.</p>
<p>What usually happens is that I get distracted&hellip; no wait, I fall down a
rabbit-hole&hellip; no wait, I actually get violently pulled into a rabbit
<strong>singularity</strong> from whence no productivity can escape.</p>
<p>The best I can do at that point, is to pour all will power into my puny arm and
click on that FOCUS button in Lazar Focus, at which point it instantly kills
everything that&rsquo;s sapping my attention, and then I again have a chance to save
the day.</p>
<p>Thanks to a recommendation by Noeska which ended up languishing in my
sub-conscious but then fortunately managed to bubble to the top, I found myself
on a wonderful site called <a href="https://mynoise.net/">myNoise</a>.</p>
<p>This is the creation of <a href="https://stephanepigeon.com/">Dr. Ir. Stéphane Pigeon</a>, a research engineer &amp; sound
designer from Belgium, who has combined noise generation as well as a library
of the highest quality recording of samples from the world over with a system
for composing these into the most amazing sound-scapes.</p>
<p>Why is this interesting, you might ask?</p>
<p>Well, in one&rsquo;s quest to block distractions of all kinds, finding the perfect
aural stimulus that is pleasant, but does not soak up attention itself, and is
also able to mask both external and internal (tinnitus, e.g.) sounds, myNoise
is exactly what the doctor ordered!</p>
<p>To give you a taste of Dr Pigeon&rsquo;s attention to detail, see for example the
<a href="https://mynoise.net/NoiseMachines/singingBowlsDroneGenerator.php">singing bowls generator</a>, and then the <a href="https://mynoise.net/NoiseMachines/enliaVocalSoundscape.php">Free-falling with vocalist Enlia
soundscape</a>.</p>
<p>Notice that in both cases you are able to customise different elements of each
soundscape with the sliders, or even press <code>A</code> to have them animate randomly
over time, morphing the landscape as you work.</p>
<p>What I only recently learned, is that Dr Pigeon designed the soundscapes to
work also simultaneously. In other words, keep the two soundscapes above open
in two browser tabs, and note how wonderfully they mesh.</p>
<p>It really feels like my brain is starting to associate high attention mode with
the mynoise soundscapes.</p>
<p>Between that and LF, we might be going places!</p>
<p>P.S. Narrator: <em>Yes, he did make a small donation to mynoise, and based on the
value he has derived since, will probably make another.</em></p>
<h2 id="what-does-it-mean-for-humanity-when-the-ai-can-derive-your-talking-face-from-your-voice-alone">What does it mean for humanity when the AI can derive your talking face from your voice alone?</h2>
<p>You might have read about <a href="https://www.theverge.com/2020/10/5/21502003/nvidia-ai-videoconferencing-maxine-platform-face-gaze-alignment-gans-compression-resolution">NVIDIA&rsquo;s new AI-based video conferencing bag of
tricks, called Maxine</a>.</p>
<p>An interesting part of this is that they use a technique, similar to deepfakes,
to send only the pose of your face over the internet, and then reconstruct a
high quality version of it on the other side.</p>
<p>From the article:</p>
<blockquote>
<p>&ldquo;Instead of streaming the entire screen of pixels, the AI software analyzes the
key facial points of each person on a call and then intelligently re-animates
the face in the video on the other side,&rdquo; said the company in a blog
post. &ldquo;This makes it possible to stream video with far less data flowing back
and forth across the internet.&rdquo;</p>
</blockquote>
<p>This made me think:</p>
<p>Soon the AI will be good enough that it can reconstruct your face from just the
audio, or maybe even text that you type.</p>
<p>This idea started as a half-serious joke, but it does raise really interesting
questions around the implications of this technology. (BTW, it is technically
entirely possible.)</p>
<p>If you&rsquo;re having a conversation with someone, and both of your faces are
indistinguishable <em>simulations</em> of the real thing, and hence help the quality
of the conversation, what does that mean for the conversation that&rsquo;s happening?</p>
<p>In other words, imagine for a second that you&rsquo;re having an intense (emotional)
conversation with someone, but the faces that both of you are seeing, are 100%
synthesised.</p>
<p>They reflect almost exactly how your faces would have looked had you had a
video link, but they are estimated by the AI.</p>
<p>Did you really have that intense conversation?</p>
<h2 id="miniburn-2020">MiniBurn 2020</h2>
<p>As you might remember from <a href="/2020/03/24/weekly-head-voices-191-covid-19-part-1/#sht-gets-real-in-mzansi">WHV #191</a>, AfrikaBurn 2020 was one of the first group
events down here that was cancelled by the pandemic.</p>
<p>Months after that, and with stats looking almost reasonable, the local subset
of our camp (THE BURNIVERSITY) decided to celebrate life together, as
responsibly as possible (which mostly comes down to: stay outside, keep your
distance), by gathering at some secret but beautiful location for the weekend.</p>
<p>(You might have deduced by now that this is one of those Burny situations where
I have no choice but to keep things as vague as they are. I still wanted to
write <strong>something</strong> as a beacon for future me. Future me, when you read this:
Read our private notes man. I left you something there.)</p>
<p>We sort of modeled the weekend like a whole Burn: Friday is arrival, setup, and
first small celebrations. Saturday represents the body of the week: Running,
workshops, celebration. Sunday is, just like it is for the full Burn, the
slightly depressing but already nostalgic clean-up, pack-up and leave the
desert stage. It&rsquo;s surprising how well this whole sequencing worked.</p>
<p>Thanks to the awe-inspiring talents of specific camp members, the cuisine was
divine and the music beautiful. Combined with the personalities and shared
memories of our small ensemble, the resultant experience was nothing short of
magic.</p>
<p>P.S. Ironically, <a href="/2020/11/12/weekly-head-voices-208-blogging-like-its-2009/#thank-you-joris">GU43 <strong>is</strong> turning into the 2020 soundtrack that I wanted</a>.</p>
]]></content:encoded></item><item><title>Weekly Head Voices #146: You too can learn Kung Fu.</title><link>https://cpbotha.net/2018/06/18/weekly-head-voices-146-you-too-can-learn-kung-fu/</link><pubDate>Mon, 18 Jun 2018 21:24:40 +0000</pubDate><author>cpbotha@cpbotha.net (Charl P. Botha)</author><guid>https://cpbotha.net/2018/06/18/weekly-head-voices-146-you-too-can-learn-kung-fu/</guid><description> This post covers the period Monday June 11 to Sunday June 17. Read it to become rich, yawn at Lisp and Emacs, yearn to run free on the wide open plains and to learn Kung Fu. Not ambitious at all. Front door nearby De Waal Park, in Cape Town. Photo taken on Sunday by GOU#1, age 12.
Social Democracy FTW It turns out that your chances of becoming rich are the greatest if you had the good fortune to have been born in one of the Nordic social democracies, such as Norway, Sweden or Denmark.</description><content:encoded><![CDATA[ <p><em>This post covers the period Monday June 11 to Sunday June 17. Read it to become rich, yawn at Lisp and Emacs, yearn to run free on the wide open plains and to learn Kung Fu. Not ambitious at all.</em>








<figure><a href="/wp-content/uploads/2018/06/IMG_2004.jpg">
    <img
        
            
            src="/wp-content/uploads/2018/06/IMG_2004-768x1024.jpg"
        
            alt="Front door nearby De Waal Park, in Cape Town. Photo taken on Sunday by GOU#1, age 12."/> </a><figcaption>
            <p>Front door nearby De Waal Park, in Cape Town. Photo taken on Sunday by GOU#1, age 12.</p>
        </figcaption>
</figure>
</p>
<h1 id="social-democracy-ftw">Social Democracy FTW</h1>
<p>It turns out that your chances of becoming rich are the greatest if you had the good fortune to have been born in one of the Nordic social democracies, such as Norway, Sweden or Denmark.</p>
<p>The US trails these countries, at position 13, in terms of per capita individuals with net worth over $30 million.</p>
<div class="jetpack-video-wrapper">
<span class="embed-youtube" style="text-align:center; display: block;"><iframe allowfullscreen="true" class="youtube-player" height="473" src="https://www.youtube.com/embed/A9UmdY0E8hU?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" style="border:0;" type="text/html" width="840"></iframe></span>
</div>
<p>Being a proponent of social democracy as the most humane form of currently practical human government, and often infuriating conservatives   by pointing out that many crucial aspects of social democracies can be described as socialistic, I really enjoyed the linked TEDx talk by Norwegian <a href="https://en.wikipedia.org/wiki/Harald_Eia">Harald Eia</a>.</p>
<p>This material will serve me well as the source of future mischief.</p>
<h1 id="paradigms-of-ai-programming-in-common-lisp">Paradigms of AI Programming in Common Lisp</h1>
<p>I am currently working my way through <a href="https://github.com/norvig/paip-lisp">“Paradigms of Artificial Intelligence Programming: Case Studies in Common Lisp”</a>, Peter Norvig’s famous 1992 book an artificial intelligence. Although modern AI has been transformed almost unrecognisably since then (THANKS DEEP LEARNING! <a href="http://norvig.com/Lisp-retro.html">Norvig’s PAIP retrospective</a>) the way in which Norvig uses Lisp to model and solve real-world problems is inspiring and quite foundational.</p>
<p>It’s not only that though.</p>
<p>My inconvenient but uncontrollable infatuation with Common Lisp also seems to be pulling the strings. I should study a real language which is not 60 years old, like Rust or something.</p>
<p>What attracts me about Common Lisp is the liberated and pragmatic way in which it enables one to mix functional, object-oriented and procedural programming, and, perhaps most importantly, how it was designed from the ground up for iterative and interactive programming.</p>
<p>Tweak the defun, eval the defun, watch the system adapt. This is what I always imagined programming would be like. Except for the Lisps, it really turned out perhaps a bit more boring than it really needs to be.</p>
<h2 id="interleave-mode-for-working-through-pdf-books">interleave-mode for working through PDF books</h2>
<p>For the fellow Emacs users, I also wanted to mention the utility of <a href="https://github.com/rudolfochrist/interleave">interleave-mode</a> for working through such a programming book, if you can find it in PDF format.</p>
<p>In my Emacs I have the PDF on the left, and my interleave-mode-linked orgfile on the right. On any page of the PDF I hit the i-button to add a note in the orgfile, where I can of course insert and execute live code snippets.</p>
<p>The sections in the orgfile remain linked to the correct pages of the PDF.</p>
<p>For programming books this is an amazing combination. For studying other books, having your orgfile notes linked will probably also be quite useful.</p>
<p>On the topic of note-taking: This past week, on Friday June 15 (I made a note of that), I was able to help a colleague solve a technical problem by searching for and retrieving an org-file note, including detailed configuration settings, that I made on May 13, 2014.</p>
<h1 id="ether-as-currency">Ether as currency</h1>
<p>Although I acquired a small amount of the Ether cryptocurrency for the first time in July of 2016, I’ve never had the opportunity to actually transact with it.</p>
<p>Up to now, it has functioned solely as a pretty volatile store of value.</p>
<p>On Saturday, I used some ether for the first time to straight-up buy something on the internet, which was a pretty exciting but in practice an uneventful procedure, fortunately.</p>
<p>The vendor used a payment processor which presented me with an address and corresponding QR code. I scanned the QR code with the relevant mobile app (Luno in this case), paid the requested amount, and waited for a few minutes for it to be multiply confirmed by the blockchain. The sending fee was about 0.04% of the transaction.</p>
<h1 id="barefoot-style-running-update">Barefoot-style running update</h1>
<p>On Sunday I went for a long(ish) run, bringing my total on the Luna sandals to just over 200km.</p>
<p>My feet, ankles and calves are much stronger than they used to be, but the barefoot conversion is clearly still has some ways to go. I have to take at the very least two rest days (instead of one) between runs to give my feet some extra time to recover.</p>
<p>What I have recently started doing, is that instead of trying to micro-manage my form (put your foot down like this, bend your ankle like that, let your achilles tendon shoot back like this, and so on), I am following the advice of some <em>new</em> random person on <a href="https://www.reddit.com/r/BarefootRunning/">reddit/r/BarefootRunning</a> who gave the advice, often echoed elsewhere by barefoot-runners, to try and maintain a cadence (steps-per-minute) of at least 180.</p>
<p>That sounds pretty high for a normal person like me, but it turns out that when I do that, and I try at the same time to run as silently as possible (I often just APPEAR right beside someone, hehe), my legs and feet figure out their elastic bio-kinematics all by themselves.</p>
<p>As yet another random reddit expert (I wish I could find the post) quipped:</p>
<blockquote>
<p>You can’t overthink proprioception.</p>
</blockquote>
<p>(that’s a running nerd joke)</p>
<h1 id="i-know-kung-fu">I know Kung Fu</h1>
<p>Do you remember this scene from The Matrix (1999)?</p>
<div class="jetpack-video-wrapper">
<span class="embed-youtube" style="text-align:center; display: block;"><iframe allowfullscreen="true" class="youtube-player" height="473" src="https://www.youtube.com/embed/V8ZdGmgj0PQ?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" style="border:0;" type="text/html" width="840"></iframe></span>
</div>
<p>The other day at the <a href="/2018/06/03/weekly-head-voices-144-eternal-learner/#reunion">Old People Reunion</a>, friend T. Monster, a highly capable pragmatist but also backyard theoretician, talked about how often it happened these days that you had to deal with some DIY issue, tapped or spoke the question into youtube, watched a video or two, and then fixed the issue like a pro.</p>
<p>This, along with my recent pseudo-expert repair of a number of stripped cabinet hinge screw holes with tooth picks and cold glue (this works, I kid you not), made me think that, although The Matrix version was perhaps far more spectacular, we in fact now find ourselves in a <em>real, shared reality</em> where a large subset of skills can be acquired <em>a la carte</em>.</p>
<p>Some may take longer than a few minutes, but it still is pretty amazing how far YouTube has managed to democratise so many different forms of modern Kung Fu.</p>
<p> </p>
<p> </p>
]]></content:encoded></item><item><title>Why it’s healthy that Microsoft and Google are eating Apple’s lunch</title><link>https://cpbotha.net/2016/11/02/why-its-healthy-that-microsoft-and-google-are-eating-apples-lunch/</link><pubDate>Wed, 02 Nov 2016 08:41:44 +0000</pubDate><author>cpbotha@cpbotha.net (Charl P. Botha)</author><guid>https://cpbotha.net/2016/11/02/why-its-healthy-that-microsoft-and-google-are-eating-apples-lunch/</guid><description> Last week Apple announced their new Macbook Pro laptops.
Their great innovation (a “game-changer” in their words) was a sliver of a touch screen above the keyboard which is able to show touchable context-specific buttons. They’ve dubbed this the TouchBar. Although the OLED technology is certainly pretty, one could almost hear the enormously disappointed collective “MEH” uttered by millions of users and suddenly erstwhile Apple fans world-wide.
Was Apple, in the form of the Phil Schiller really trying to sell this?</description><content:encoded><![CDATA[ <p>Last week Apple announced their new Macbook Pro laptops.</p>
<p>Their great innovation (a “game-changer” in their words) was a sliver of a touch screen above the keyboard which is able to show touchable context-specific buttons. They’ve dubbed this the TouchBar. Although the OLED technology is certainly pretty, one could almost hear the enormously disappointed collective “MEH” uttered by millions of users and suddenly erstwhile Apple fans world-wide.</p>
<p>Was Apple, in the form of the Phil Schiller really trying to sell this? By the way, if you represent Apple, a company traditionally known for its great design sensibilities, should you not spend just a little more money to dress a little better than the couture equivalent of an old Lada? Suit up man!








<figure><a href="/wp-content/uploads/2016/11/2016-11-02-104946_304x456_scrot.png">
    <img
        
            
            src="/wp-content/uploads/2016/11/2016-11-02-104946_304x456_scrot.png"
        
            alt="Phil Schiller not suiting up."/> </a><figcaption>
            <p>Phil Schiller not suiting up.</p>
        </figcaption>
</figure>
</p>
<p>Collectively, the internet <a href="http://www.huffingtonpost.com/entry/new-apple-macbook-pro_us_58123abde4b064e1b4b0fd76">was disappointed</a>. Why no touch screen? Why no new iMac (last refresh a year ago) or Mac Pro (last refresh 3 years ago)? <a href="https://milen.me/writings/mac-platform-decline/">What is happening at Apple</a>?</p>
<p>The day before, on October 26, 2016, Microsoft revealed the Surface Studio. Watch this introduction:</p>
<div class="jetpack-video-wrapper">
<span class="embed-youtube" style="text-align:center; display: block;"><iframe allowfullscreen="true" class="youtube-player" height="473" src="https://www.youtube.com/embed/BzMLA8YIgG0?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" style="border:0;" type="text/html" width="840"></iframe></span>
</div>
<p>… and also this video with Microsoft partners who have in secret been working with the Studio:</p>
<div class="jetpack-video-wrapper">
<span class="embed-youtube" style="text-align:center; display: block;"><iframe allowfullscreen="true" class="youtube-player" height="473" src="https://www.youtube.com/embed/WMklcdzcNcU?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" style="border:0;" type="text/html" width="840"></iframe></span>
</div>
<p>Even if you did not like Microsoft, you can get a good sense of the emotion around this new product.</p>
<p>They’ve managed to make something that speaks to the imagination. When I see this, as an outspoken Microsoft critic, I do get the distinct feeling that the Surface Studio is a physical artefact of the science fiction dream that my reality is gradually (and very pleasingly) turning into. My less nerdy technology-critical better half’s first reaction was: <strong><em>When can we get this?</em></strong></p>
<p>It seems that Microsoft has convincingly out-Appled Apple.</p>
<p>In other words, Microsoft has somehow become sexy whilst Apple seems to have developed strong feelings for the Lada.</p>
<p>As an interesting related tidbit, a friend, whom I was trying to convince NOT to get Google’s new Pixel XL phone because reasons, recently sent me <a href="http://www.theverge.com/circuitbreaker/2016/10/29/13466786/google-pixel-photo-better-than-iphone">this short post on The Verge</a> by Vlad Savov, a camera phone expert who until recently was of the educated opinion that the iPhone 7 was still the king of the smartphone castle. He writes:</p>
<blockquote>
<p>On the basis of my extended experience with Google’s Pixel, I consider it an all-around better phone than the iPhone 7. The final exhilarating straw that broke the camel’s back was the photo below, coming straight out of the Pixel XL’s camera, undoctored other than for a horizon adjustment.</p>
</blockquote>
<p>WHAT IN HEAVENS IS HAPPENING?! OUR WHOLE WORLD IS COLLAPSING!</p>
<p>Perhaps not…</p>
<p>During a Signal App conversation (you should really use Signal, it now has <a href="https://www.whispersystems.org/blog/giphy-experiment/">privacy-conscious Giphy support</a>) with <a href="http://francoismalan.com/">another friend</a>, I realised that what’s happening here, is in fact <strong>wonderfully capricious human emotion interfering with the machine that is capitalism</strong>.</p>
<p>Left to its own devices, the nature of capitalism means that successful companies tend to evolve into capitalistically optimal dead ends. In other words, large successful companies lose the will to innovate, because they realise they are able to make more money at less risk by simply not rocking that boat. Instead of investing in innovation, they invest in sales and marketing to milk their large customer-base.</p>
<p>Ironically, Steve Jobs explained this idea quite eloquently during this interview where he talked about the decline of Xerox:</p>
<div class="jetpack-video-wrapper">
<span class="embed-youtube" style="text-align:center; display: block;"><iframe allowfullscreen="true" class="youtube-player" height="473" src="https://www.youtube.com/embed/_1rXqD6M614?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" style="border:0;" type="text/html" width="840"></iframe></span>
</div>
<p>Fortunately, when a company like Microsoft throws an innovation curve-ball that appeals to our emotion and to our imagination, they can rock the boat for everyone.</p>
<p>Even although we’re talking about three absolute behemoths, it’s gratifying that they, as well as their smaller competitors, keep each other on their toes through the fickle wonder that is human behaviour.</p>
<p>Here’s to hoping that AI never manages to model or predict our precious caprice. :)</p>
]]></content:encoded></item></channel></rss>