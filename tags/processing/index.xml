<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Processing on voices in my head</title><link>https://cpbotha.net/tags/processing/</link><description>Recent content in Processing on voices in my head</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Fri, 04 Mar 2011 20:44:27 +0000</lastBuildDate><atom:link href="https://cpbotha.net/tags/processing/index.xml" rel="self" type="application/rss+xml"/><item><title>I crushed the GSVideo problematic frame error!</title><link>https://cpbotha.net/2011/03/04/i-crushed-the-gsvideo-problematic-frame-error/</link><pubDate>Fri, 04 Mar 2011 20:44:27 +0000</pubDate><guid>https://cpbotha.net/2011/03/04/i-crushed-the-gsvideo-problematic-frame-error/</guid><description>Nerd warning: This post really belongs on my nerd blog VXLabs.com, but as this blog has a rich tradition of popular [processing posts][2], I’m posting it here.
[][3]
[GSVideo][4] is a brilliant library that you can use in [processing][5] to capture live video, on Windows, Linux and OSX, and it’s a huge improvement over the built-in capturing support. Unfortunately, a number of us (including some of the 123 students we got to build augmented reality music instruments this September) have been running into a problematic frame error crash that meant captures didn’t last for very long before unceremoniously crashing the application. Error info and stack trace look something like the following (edited for brevity):</description><content:encoded><![CDATA[ <p><em>Nerd warning: This post really belongs on my nerd blog <a href="http://vxlabs.com/" title="VXLabs.com, my favourite nerd blog!">VXLabs.com</a>, but as this blog has a rich tradition of popular [processing posts][2], I’m posting it here.</em></p>
<p>[<img alt="Debugging" height="180" src="http://farm3.static.flickr.com/2676/4047355843_0fd2fa0036_m.jpg" width="240"/>][3]</p>
<p>[GSVideo][4] is a brilliant library that you can use in [processing][5] to capture live video, on Windows, Linux and OSX, and it’s a huge improvement over the built-in capturing support. Unfortunately, a number of us (including some of the 123 students we got to build augmented reality music instruments this September) have been running into a problematic frame error crash that meant captures didn’t last for very long before unceremoniously crashing the application. Error info and stack trace look something like the following (edited for brevity):</p>
<pre class="brush: plain; title: ; notranslate" title=""># A fatal error has been detected by the Java Runtime Environment:
#
#  EXCEPTION_ACCESS_VIOLATION (0xc0000005) at pc=0x7c342eee, pid=1564, tid=2052
#
# JRE version: 6.0_20-b02
# Java VM: Java HotSpot(TM) Client VM (16.3-b01 mixed mode windows-x86 )
# Problematic frame:
# C  [msvcr71.dll+0x2eee]
#
---------------  T H R E A D  ---------------

Current thread (0x18db7000):  JavaThread "Animation Thread" [_thread_in_native, id=2052, stack(0x1bfd0000,0x1c020000)]

Stack: [0x1bfd0000,0x1c020000],  sp=0x1c01f8a0,  free space=13e1c01f384k
Native frames: (J=compiled Java code, j=interpreted, Vv=VM code, C=native code)
C  [msvcr71.dll+0x2eee]
C  [java.dll+0x728d]
J  java.nio.Bits.copyToByteArray(JLjava/lang/Object;JJ)V
j  java.nio.DirectIntBufferU.get([III)Ljava/nio/IntBuffer;+126
j  java.nio.IntBuffer.get([I)Ljava/nio/IntBuffer;+5
j  codeanticode.gsvideo.GSCapture.read()V+24
j  CathetAR.draw()V+22
</pre>
<p>Read more about it on this [forum thread][6].</p>
<p>In any case, today I spent some hours I don’t really have and finally managed to crush it. Turns out, and some of you will probably not be surprised, that it was a threading problem. The capture event handler invokeEvent() and the read() call were being interleaved, and the buffer they were using is also not thread-safe. Doh. Some synchronization here and there, and an extra capture buffer, now I can’t get it to crash anymore.</p>
<p>Get the [patch here][7], and a [patched GSVideo.jar][8] here. Both of these are for the GSVideo 20110203 test version. If you can’t patch and build it yourself, just copy my GSVideo.jar over the GSVideo.jar in your unpacked GSVideo 20110203 plugin directory (sub-directory library). <strong>Update: See below, GSVideo 0.8 has been released and now contains my patch. Rather get the 0.8 download!</strong></p>
<p>Leave me a comment if this helps!</p>
<h3 id="update-on-2011-03-06">Update on 2011-03-06</h3>
<p>Andres Colubri, author of GSVideo, has refined and [integrated][9] my patch. The next GSVideo release (0.8 and newer) should have this fix.</p>
<h3 id="update-on-2011-03-15">Update on 2011-03-15</h3>
<p>Andres has just released GSVideo 0.8, which integrates my fix and many other improvements. Go read his [0.8 release post][10]!</p>
<p>[2]: /tag/processing/ &ldquo;All posts on this site tagged with &ldquo;processing&rdquo;.&rdquo;
[3]: <a href="http://www.flickr.com/photos/28208534@N07/4047355843/">http://www.flickr.com/photos/28208534@N07/4047355843/</a> &ldquo;Debugging by mikemol, on Flickr&rdquo;
[4]: <a href="http://gsvideo.sourceforge.net/">http://gsvideo.sourceforge.net/</a> &ldquo;GSVideo website&rdquo;
[5]: <a href="http://processing.org/">http://processing.org/</a> &ldquo;processing website&rdquo;
[6]: <a href="http://forum.processing.org/topic/gsvideo-0-6-crash-problem">http://forum.processing.org/topic/gsvideo-0-6-crash-problem</a> &ldquo;forum thread 1 concerning the problematic frame crash&rdquo;
[7]: <a href="http://cpbotha.net/files/gsvideo-20110203-patch-20110304/gsvideo-20110203-problematic-frame-fix-cpbotha.diff">http://cpbotha.net/files/gsvideo-20110203-patch-20110304/gsvideo-20110203-problematic-frame-fix-cpbotha.diff</a> &ldquo;gsvideo problematic frame fix&rdquo;
[8]: <a href="http://cpbotha.net/files/gsvideo-20110203-patch-20110304/GSVideo.jar">http://cpbotha.net/files/gsvideo-20110203-patch-20110304/GSVideo.jar</a> &ldquo;patched and built GSVideo.jar&rdquo;
[9]: <a href="http://gsvideo.svn.sourceforge.net/viewvc/gsvideo/trunk/src/codeanticode/gsvideo/GSCapture.java?r1=152&amp;r2=151&amp;pathrev=152">http://gsvideo.svn.sourceforge.net/viewvc/gsvideo/trunk/src/codeanticode/gsvideo/GSCapture.java?r1=152&amp;r2=151&amp;pathrev=152</a> &ldquo;gsvideo changeset integrating crash fix&rdquo;
[10]: <a href="http://codeanticode.wordpress.com/2011/03/15/gsvideo-0-8/">http://codeanticode.wordpress.com/2011/03/15/gsvideo-0-8/</a> &ldquo;gsvideo 0.8 release post&rdquo;</p>
 ]]></content:encoded></item><item><title>Processing + NyARToolkit + multiple marker tracking</title><link>https://cpbotha.net/2010/06/05/processing-nyartoolkit-multiple-marker-tracking/</link><pubDate>Sat, 05 Jun 2010 22:59:24 +0000</pubDate><guid>https://cpbotha.net/2010/06/05/processing-nyartoolkit-multiple-marker-tracking/</guid><description>For various reasons, I need to do multiple marker tracking in processing with NyARToolkit. However, with the default NyAR4psg layer between these two, multiple marker tracking is downright hard, and when you get it working, it’s not quite what you expect. After a few days of Java hacking, during which I was very pleasantly surprised with eclipse, I am now pleased to present to you my modifications to the NyAR4psg that makes multiple marker tracking easy! See here: Standard hiro and kanji markers tracked simultaneously with augmented reality sphere and cube. In the background some artwork by my daughter!</description><content:encoded><![CDATA[ <p>For various reasons, I need to do multiple marker tracking in <a href="http://processing.org/" title="processing website">processing</a> with <a href="http://nyatla.jp/nyartoolkit/wiki/index.php?FrontPage.en" title="NyARToolkit website">NyARToolkit</a>.  However, with the default <a href="http://nyatla.jp/nyartoolkit/wiki/index.php?NyAR4psg.en" title="Link to NyAR4psg page">NyAR4psg</a> layer between these two, multiple marker tracking is downright hard, and when you get it working, it’s not quite what you expect. After a few days of Java hacking, during which I was very pleasantly surprised with eclipse, I am now pleased to present to you my modifications to the NyAR4psg that makes multiple marker tracking easy! See here:










<figure><a href="/wp-content/uploads/2010/06/nyarmultiboard_ss.jpg">
    <img
        
            
            src="/wp-content/uploads/2010/06/nyarmultiboard_ss.jpg"
        
            alt="Standard hiro and kanji markers tracked simultaneously with augmented reality sphere and cube. In the background some artwork by my daughter!"/> </a><figcaption>
            <p>Standard hiro and kanji markers tracked simultaneously with augmented reality sphere and cube. In the background some artwork by my daughter!</p>
        </figcaption>
</figure>
</p>
<p>I’ve called it NyARMultiBoard, and you can use it instead of the default NyARBoard if you want to track multiple markers.</p>
<p>Download a ZIP file containing everything (source code, jar files) from <a href="http://cpbotha.net/files/nyar4psg_multimarker/" title="Link to NyARMultiBoard archive">this directory</a>.  If you unpack this into your processing sketchbook/libraries directory, it should work out of the box.  It’s a drop-in replacement for NyAR4psg, so you don’t need to have that installed as well. There is an example to get you started in NyAR2/example/NyARMultiTest.  Note: This uses the GSVideo capturing stack as I explain <a href="http://cpbotha.net/2010/03/04/processing-gsvideo-nyartoolkit-on-linux-x86_64/" title="howto getting gsvideo going on x76_64">here</a>, you should easily be able to change it back to processing defaults (just change GSCapture to Capture).</p>
<p><em>Please let me know in the comments if this works (or doesn’t) for you!</em></p>
<p>I made this screencast to demonstrate the multiple marker tracking, assisted by <a href="http://cpbotha.net/2009/09/20/weekly-head-voices-4-the-new-roomie-medvis-at-mevis-fairy-tale-beach/" title="The New Roomie blog">TNR</a>:</p>
<div class="jetpack-video-wrapper">
<span class="embed-youtube" style="text-align:center; display: block;"><iframe allowfullscreen="true" class="youtube-player" height="473" src="https://www.youtube.com/embed/a9nXZqtkrsk?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" style="border:0;" type="text/html" width="840"></iframe></span>
</div>
<p>I also made this really bad screencast (old webcam + night time lighting + transcoding):</p>
<div class="jetpack-video-wrapper">
<span class="embed-youtube" style="text-align:center; display: block;"><iframe allowfullscreen="true" class="youtube-player" height="473" src="https://www.youtube.com/embed/5qAMUM7Z1_4?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" style="border:0;" type="text/html" width="840"></iframe></span>
</div>
<p><strong>If you’re really into the details</strong></p>
<p>I’ve just added two new classes NyARMultiBoard and NyARMultiBoardMarker to the default NyAR4psg distribution. Very importantly, NyARToolkit itself needs to be patched with one extra method in NyARDetectMarker, see the NyARMultiBoard comments.</p>
<p><strong>Update on 20110304</strong></p>
<p>I’ve fixed the problematic frame bug in gsvideo that many of you have been running into. See <a href="http://cpbotha.net/2011/03/04/i-crushed-the-gsvideo-problematic-frame-error/" title="post with gsvideo problematic frame error fix">this post</a>.</p>
<p><strong>Update on 20110305</strong></p>
<p>I’ve updated NyAR2 so it works with the P3D renderer as well, which is often faster for blitting the webcam image onto the display. The updated zip file is named NyAR2-20110305.zip, and it can be downloaded from the <a href="http://cpbotha.net/files/nyar4psg_multimarker/" title="NyAR2 multimarker download directory.">usual directory</a>. My changes are based on NyAR4psg 0.3.0 and NyARToolkit 2.5.2.</p>
 ]]></content:encoded></item><item><title>Processing + GSVideo + NyARToolkit on Linux x86_64</title><link>https://cpbotha.net/2010/03/04/processing-gsvideo-nyartoolkit-on-linux-x86_64/</link><pubDate>Thu, 04 Mar 2010 22:41:48 +0000</pubDate><guid>https://cpbotha.net/2010/03/04/processing-gsvideo-nyartoolkit-on-linux-x86_64/</guid><description>Every now and then, I blast out the cruft from my nerd gland’s exit duct by writing a terribly nerdy post. This is just such a post, so if you don’t speak Nerd, i’d highly recommend that you go have some fun elsewhere, at least until my next Weekly Head Voices of course!
As mentioned around these parts, I’m currently playing with Processing, a beautiful programming stack for making interactive visual, err, thingies. To be more specific, I’d like to use processing together with something like ARToolkit to do real-time 3D tracking of markers in live video, for augmented reality fun. To see what this could look like, see this YouTube video:</description><content:encoded><![CDATA[ <p>Every now and then, I blast out the cruft from my nerd gland’s exit duct by writing a terribly nerdy post.  This is just such a post, so if you don’t speak Nerd, i’d highly recommend that you go have some fun <a href="http://chatroulette.com/" title="fun random webcam site">elsewhere</a>, at least until my next Weekly Head Voices of course!</p>
<p>As mentioned around these parts, I’m currently playing with <a href="http://processing.org/" title="Processing website">Processing</a>, a beautiful programming stack for making interactive visual, err, thingies. To be more specific, I’d like to use processing together with something like ARToolkit to do real-time 3D tracking of markers in live video, for augmented reality fun.  To see what this could look like, see this YouTube video:</p>
<div class="jetpack-video-wrapper">
<span class="embed-youtube" style="text-align:center; display: block;"><iframe allowfullscreen="true" class="youtube-player" height="473" src="https://www.youtube.com/embed/uoncHfnYWHM?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" style="border:0;" type="text/html" width="840"></iframe></span>
</div>
<p>Today’s challenge is getting whole stack, including processing, the GSVideo video capture library for processing and the NyARToolkit augmented reality for processing going on Linux x86_64 (64bit).  On Linux x86 (32bit) this is much more straight-forward, but I wouldn’t write a blog post about straight-forward, now would I?</p>
<p>Here is the recipe:</p>
<ol>
<li>
<p>Make sure you have the native 64bit Sun JDK installed for your system.  On this Ubuntu 9.10 machine it’s ﻿﻿﻿sun-java6-jdk 6-15-1, on Ubuntu 10.04 (also tested) it’s ﻿6.20dlj-1ubuntu3.</p>
</li>
<li>
<p>Also install the jogl libraries, on this machine called libjogl-java.</p>
</li>
<li>
<p>Make sure you have the whole of gstreamer installed. On ubuntu, all packages containing “gstreamer”.</p>
</li>
<li>
<p>Get and unpack the processing for Linux tarball (I’ve tested this whole procedure with processing 1.0.9, 1.1 and 1.2.1) from the processing <a href="http://processing.org/download/" title="processing download site">download site</a>.</p>
</li>
<li>
<p>In the unpacked processing directory, remove the whole java subdirectory. Now make a symlink pointing to your system java directory (the one containing bin, ext, jre, lib, etc.).  On my system, that was: <pre class="brush: bash; title: ; notranslate" title="">cd processing
rm -rf java
ln -s /usr/lib/jvm/java-6-sun-1.6.0.15﻿ java
</pre></p>
</li>
<li>
<p>In processing/libraries/opengl/library remove the 3 libjogl*.so files and libgluegen-rt.so. Symlink their replacements from /usr/lib/jni with for example: <pre class="brush: bash; title: ; notranslate" title="">cd processing/libraries/opengl/library
rm lib*.so
ln -s /usr/lib/jni/libgluegen-rt.so
ln -s /usr/lib/jni/libjogl_awt.so
ln -s /usr/lib/jni/libjogl.so
</pre></p>
</li>
<li>
<p><a href="http://users.design.ucla.edu/~acolubri/processing/gsvideo/home/" title="GSVideo website">Download</a> and unpack gsvideo into processing/libraries.  You should be able to run the examples in processing/libraries/gsvideo/examples/Capture with the PDE (Processing Development Environment).</p>
</li>
<li>
<p><a href="http://nyatla.jp/nyartoolkit/wiki/index.php?NyAR4psg.en" title="NyARToolkit for Processing website">Download</a> and unpack the NyARToolkit for Processing library into processing/libraries.</p>
</li>
</ol>
<p>You should now be able to run the NyARToolkit examples by changing replacing the import call as follows:</p>
<pre class="brush: java; title: ; notranslate" title="">// replace this call:
// import processing.video.*;
// by this call:
import codeanticode.gsvideo.*;
</pre>
<p>and changing the Capture class (twice) to GSCapture and perhaps also the capture resolution, depending on your camera. The relevant conversions are:</p>
<pre class="brush: java; title: ; notranslate" title="">// Capture cam;
// becomes:
GSCapture cam;

// later, in setup():
// cam=new Capture(this,width,height);
// becomes:
cam=new GSCapture(this,width,height);
</pre>
<p>The major trick in all of this is converting your Processing installation to use your system 64bit JDK instead of its own built-in 32bit JDK.</p>
<p>Let me know in the comments if this worked (or didn’t) for you!</p>
 ]]></content:encoded></item></channel></rss>