<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Llm on voices in my head</title><link>https://cpbotha.net/tags/llm/</link><description>Recent content in Llm on voices in my head</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Sun, 28 Jan 2024 21:27:48 +0200</lastBuildDate><atom:link href="https://cpbotha.net/tags/llm/index.xml" rel="self" type="application/rss+xml"/><item><title>Daily Head Voices for week 4 of 2024</title><link>https://cpbotha.net/2024/01/28/daily-head-voices-2024-01-22_28/</link><pubDate>Sun, 28 Jan 2024 21:27:00 +0200</pubDate><guid>https://cpbotha.net/2024/01/28/daily-head-voices-2024-01-22_28/</guid><description>Monday 2024-01-22 As GOU#1 and GOU#2 were busy leaving for school, #3 came in to #2 for a hug but #2 was a bit too focused on getting all of her things ready to go in the car. Good Charl, in his only appearance of the day, spontaneously interjected with: &amp;ldquo;When you&amp;rsquo;re in a hug, for that moment, you put your full attention into that hug. For that moment, nothing else exists but the hug.&amp;rdquo;. I could really see the message hitting home with #2, and she vocalised as much. Monday: BIG SUCCESS! At work, managed to spill black coffee all over meself as I was just doing step 1 of living the one cable dream (read: attaching usb-c cable to my macbook). Clumsy Charl clearly at the wheel&amp;hellip; Short but really nice streamlit demo during a work meeting. I knew about streamlit, but I&amp;rsquo;ve never actually played with it. Spent the rest of the day fighting trying, without success, to update the webcola d3 adapter to the latest version of d3. In bed that night, had light-bulb that React was probably a better solution for this visualization in any case&amp;hellip; &amp;hellip; and then realised that few years back I built something similar for work, and had a similar evolution of ideas which ended up with react + webcola. Tuesday 2024-01-23 At the office nice and early (7:30). Chatted with colleague about the abovementioned React + webcola thing we worked on together, at which point he pointed me at react-flow and comfyui react-flow looks like it could work pretty well for this new project. Also: SO SHINY! streamlit app life cycle: script re-runs every time user interacts, see https://docs.streamlit.io/get-started/fundamentals/summary it does have caching mechanisms to make this go faster marimo, although much newer, approaches this issue with its reactive cell pattern Idea: We should write focused technical memos at work. This is now howto, but rather &amp;ldquo;things I learned&amp;rdquo; formulated to teach not just to document. Upgaded phone to iOS 17.3 and MacBook to macOS 14.3. Apparently there&amp;rsquo;s a zero day vulnerability in previous versions that can be exploited via malicious websites. Wednesday 2024-01-24 8km run at just after 7 AM before it really got hot dip in the pool (friend LM says we must but pool is probably not cold enough due to +30℃ temps), then started to work right after dip in pool, partially pulled back muscle. Partial, because two warning spasms, but not complete lock like many previous times. PHEW! Remember kids: Our spine&amp;rsquo;s vertical operation is a major evolutionary hack job and a mechanical disaster just waiting to happen. My advice: Spend more time horizontally. This is also the reason why I&amp;rsquo;m still searching for a long enough reclining chair. Lovely working lunch with friend S at No Way José Some random ideas that popped into my head as I was trying to work: idea: make github so that people can pipx install marimo-turbo to get install with pandas, altair, matplotlib, and so on. idea: figure out way to publish marimo dashboard to HTTPS url somewhere, for really really cheap sounds like AWS API gateway + lambdas can do something complicated to host streamlit, which also uses websockets in the end, probably better to do this on my own VPS &amp;hellip; or even better, on my own machine behind tailscale funnel! This was straight-forward and seems to work well. See https://emacs.ch/@cpbotha/111811547009420844 (post is also embedded below) idea: (which has been active for a bit longer) A reliable pattern to lazy start upstream processes only when the first request comes in, and to stop them when no-one is connected. Client -&amp;gt; nginx -&amp;gt; supervisord -&amp;gt; tornado systemd can partially do something like this using socket activation: https://serverfault.com/questions/1121584/start-apache-on-demand-using-systemd-socket-activation I would prefer to use supervisord for this This will remain on the todo list for now, unless one of you knows a trick? ran into dude who built kubernetes thing for Hetzner using Crystal, a programming language of which I remembered that it just had a release, so quickly lost some more time on &amp;ldquo;crystal vs nim-lang&amp;rdquo; googling blog post: https://vitobotta.com/2023/01/07/kubernetes-on-hetzner-cloud-the-easiest-way/ the kubernetes thing: https://github.com/vitobotta/hetzner-k3s TIL: mastodon embeds are not as durable as twitter embeds As I pasted the above embed, I saw to my disappointment that it&amp;rsquo;s just pulling in the mastodon post URL via iframe.</description><content:encoded><![CDATA[ <h2 id="monday-2024-01-22">Monday 2024-01-22</h2>
<ul>
<li>As GOU#1 and GOU#2 were busy leaving for school, #3 came in to #2 for a hug but #2 was a bit too focused on getting all of her things ready to go in the car. Good Charl, in his only appearance of the day, spontaneously interjected with: &ldquo;When you&rsquo;re in a hug, for that moment, you put your full attention into that hug. For that moment, nothing else exists but the hug.&rdquo;. I could really see the message hitting home with #2, and she vocalised as much. Monday: BIG SUCCESS!</li>
<li>At work, managed to spill black coffee all over meself as I was just doing step 1 of living the one cable dream (read: attaching usb-c cable to my macbook). Clumsy Charl clearly at the wheel&hellip;</li>
<li>Short but really nice <a href="https://streamlit.io/">streamlit</a> demo during a work meeting. I knew about streamlit, but I&rsquo;ve never actually played with it.</li>
<li>Spent the rest of the day fighting trying, without success, to update the webcola d3 adapter to the latest version of d3.
<ul>
<li>In bed that night, had light-bulb that React was probably a better solution for this visualization in any case&hellip;</li>
<li>&hellip; and then realised that few years back I built something similar for work, and had a similar evolution of ideas which ended up with react + webcola.</li>
</ul>
</li>
</ul>
<h2 id="tuesday-2024-01-23">Tuesday 2024-01-23</h2>
<ul>
<li>At the office nice and early (7:30).</li>
<li>Chatted with colleague about the abovementioned React + webcola thing we worked on together, at which point he pointed me at <a href="https://reactflow.dev/">react-flow</a> and comfyui
<ul>
<li>react-flow looks like it could work pretty well for this new project. Also: SO SHINY!</li>
</ul>
</li>
<li>streamlit app life cycle: script re-runs every time user interacts, see <a href="https://docs.streamlit.io/get-started/fundamentals/summary">https://docs.streamlit.io/get-started/fundamentals/summary</a>
<ul>
<li>it does have caching mechanisms to make this go faster</li>
<li>marimo, although much newer, approaches this issue with its reactive cell pattern</li>
</ul>
</li>
<li>Idea: We should write focused technical memos at work. This is now howto, but rather &ldquo;things I learned&rdquo; formulated to teach not just to document.</li>
<li>Upgaded phone to iOS 17.3 and MacBook to macOS 14.3. Apparently there&rsquo;s a <a href="https://www.tomsguide.com/news/apple-issues-urgent-security-updates-to-fix-zero-day-flaw-update-your-iphone-and-mac-right-now">zero day vulnerability</a> in previous versions that can be exploited via malicious websites.</li>
</ul>
<h2 id="wednesday-2024-01-24">Wednesday 2024-01-24</h2>
<ul>
<li>8km run at just after 7 AM before it really got hot</li>
<li>dip in the pool (friend LM says we must but pool is probably not cold enough due to +30℃ temps), then started to work</li>
<li>right after dip in pool, partially pulled back muscle. Partial, because two warning spasms, but not complete lock like many previous times. PHEW!
<ul>
<li>Remember kids: Our spine&rsquo;s vertical operation is a major evolutionary hack job and a mechanical disaster just waiting to happen. My advice: Spend more time horizontally.</li>
<li>This is also the reason why I&rsquo;m still searching for a long enough reclining chair.</li>
</ul>
</li>
<li>Lovely working lunch with friend S at <a href="https://www.facebook.com/NoWayJoseSomerset">No Way José</a></li>
<li>Some random ideas that popped into my head as I was trying to work:
<ul>
<li>idea: make github so that people can <code>pipx install marimo-turbo</code> to get install with pandas, altair, matplotlib, and so on.</li>
<li>idea: figure out way to publish marimo dashboard to HTTPS url somewhere, for really really cheap
<ul>
<li>sounds like AWS API gateway + lambdas can do something complicated to host streamlit, which also uses websockets</li>
<li>in the end, probably better to do this on my own VPS
<ul>
<li>&hellip; or even better, on my own machine behind tailscale funnel! This was straight-forward and seems to work well. See <a href="https://emacs.ch/@cpbotha/111811547009420844">https://emacs.ch/@cpbotha/111811547009420844</a> (post is also embedded below)</li>
</ul>
</li>
</ul>
</li>
<li>idea: (which has been active for a bit longer) A reliable pattern to lazy start upstream processes only when the first request comes in, and to stop them when no-one is connected. Client -&gt; nginx -&gt; supervisord -&gt; tornado
<ul>
<li>systemd can partially do something like this using socket activation: <a href="https://serverfault.com/questions/1121584/start-apache-on-demand-using-systemd-socket-activation">https://serverfault.com/questions/1121584/start-apache-on-demand-using-systemd-socket-activation</a></li>
<li>I would prefer to use supervisord for this</li>
<li>This will remain on the todo list for now, unless one of you knows a trick?</li>
</ul>
</li>
</ul>
</li>
<li>ran into dude who built kubernetes thing for Hetzner using Crystal, a programming language of which I remembered that it just had a release, so quickly lost some more time on &ldquo;crystal vs nim-lang&rdquo; googling
<ul>
<li>blog post: <a href="https://vitobotta.com/2023/01/07/kubernetes-on-hetzner-cloud-the-easiest-way/">https://vitobotta.com/2023/01/07/kubernetes-on-hetzner-cloud-the-easiest-way/</a></li>
<li>the kubernetes thing: <a href="https://github.com/vitobotta/hetzner-k3s">https://github.com/vitobotta/hetzner-k3s</a></li>
</ul>
</li>
</ul>
<iframe src="https://emacs.ch/@cpbotha/111811547009420844/embed" class="mastodon-embed" style="max-width: 100%; border: 0" width="400" allowfullscreen="allowfullscreen"></iframe><script src="https://emacs.ch/embed.js" async="async"></script>
<h3 id="til-mastodon-embeds-are-not-as-durable-as-twitter-embeds">TIL: mastodon embeds are not as durable as twitter embeds</h3>
<p>As I pasted the above embed, I saw to my disappointment that it&rsquo;s just pulling in the mastodon post URL via <code>iframe</code>.</p>
<p>With twitter, you get more self-contained HTML which will render even when twitter or just the original tweet don&rsquo;t exist anymore.</p>
<p>This is probably just another reason to figure out how I can get more low-friction microblogging going on my own websites so that the embedding implementations of other microblogging sites become irrelevant.</p>
<h2 id="thursday-2024-01-25">Thursday 2024-01-25</h2>
<ul>
<li>Took a look at <a href="https://developers.cloudflare.com/cloudflare-one/connections/connect-networks/get-started/">cloudflare tunnels</a> to expose marimo and other dashboards to the internet
<ul>
<li>great that I can use my existing domains for this, and I can route between multiple domains to multiple locally running services</li>
<li>some more steps to setup, but it did not take more than about 5 minutes, and gives me even more options than tailscale funnels. OPTIONS MAN!</li>
</ul>
</li>
<li>At work, quickly got react-flow&hellip; flowing. SHINY!</li>
<li>In the evening, found <a href="https://www.macstories.net/stories/generating-markdown-links-to-mail-messages-with-shortcuts-and-applescript/">https://www.macstories.net/stories/generating-markdown-links-to-mail-messages-with-shortcuts-and-applescript/</a> which is the new Shortcuts based way, based on the old AppleScript way, of getting a <code>message://</code> link onto the clipboard.
<ul>
<li>You <a href="/2023/04/11/note-taking-strategy-2023/#email-linking">might recall from this blog</a> that <code>message://</code> are the most durable and cross-platform way to link to emails from your notes (or anywhere else)</li>
</ul>
</li>
</ul>
<h2 id="friday-2024-01-26">Friday 2024-01-26</h2>
<ul>
<li>Woke up to cool, overcast weather, a big change from a series of 30℃ + days. Really had to resist going out for a run (normal run day + that amazing coolness), because of Wednesday&rsquo;s partially pulled back muscle not being 100% yet.</li>
<li>Worked on mystery visualization project (react-flow)</li>
<li>Lovely and energising lunch with previous colleague and friend. Happy that I reached out on Thursday although they have a packed schedule because only in country for limited time. I guess this is quite related to <a href="/2022/09/25/weekly-head-voices-246-call-up-your-friends/#call-up-your-friends">calling up your friends</a>, with a ping of serendipity salt.</li>
<li>I was shocked by how well and fast <a href="https://ollama.ai/">ollama</a> worked on my MacBook. See embedded tweet below.</li>
<li>Almost at the end of the afternoon, friend S and I went to some more friends for the first Weiss-off, that is, a Weiss beer tasting contest. It was huge fun blind-tasting 10 different Weiss beers, ranking them, trying to identify them (so much harder than I thought!), and then having them revealed at the end.
<ul>
<li>Between the experts there (read: us), Stangen Weiss Bier came out on top, followed by Weisbier No5 and Jack Black Atlantic Weiss. The fourth place was shared by Erdinger and CBC Amber Weiss.</li>
<li>My favourite, Stellenbrau Jonkersweiss, is glaringly absent from the top. I&rsquo;ll live, probably consoled by just such a Jonkersweiss. Super happy that Amber Weiss and Atlantic are both present!</li>
<li>There was a trophy (for the taster who could blind-identify the most beers in the Weiss-off), which we have christened the <em>David Weisselhoff wisseltrofee</em>.</li>
</ul>
</li>
</ul>
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">With <a href="https://twitter.com/MistralAI?ref_src=twsrc%5Etfw">@MistralAI</a>&#39;s Mistral 7B at Q4_0 on this MacBook M1 Pro 10C / 16C, <a href="https://twitter.com/ollama?ref_src=twsrc%5Etfw">@ollama</a> looks like it&#39;s easily 3 times faster than the new MLX 0.0.11 (with GGUF support).<br><br>It&#39;s subjectively (visually) faster, and the tokens/s measurements confirm this. <a href="https://t.co/9vyluimLKK">pic.twitter.com/9vyluimLKK</a></p>&mdash; @cpbotha@emacs.ch (@cvoxel) <a href="https://twitter.com/cvoxel/status/1750824125419942036?ref_src=twsrc%5Etfw">January 26, 2024</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<h2 id="saturday-2024-01-27">Saturday 2024-01-27</h2>
<ul>
<li>Yesterday&rsquo;s Wonderful Weiss-off also had some, thankfully quite minor, effect the next morning, but I went out for a careful weekday distance run, which fortunately went without a hitch. Just very hot thanks.</li>
<li>Went to Buco and then to <a href="https://appletoolandgas.com/">Apple Tool and Gas</a> to find the rest of the screws I needed to repair the shower door. Friendly gentleman at Apple even sawed some of my screws to size! Shower door back in operation.</li>
<li>Updated my &ldquo;old&rdquo; M1 MBA to macOS 14.3 and then reset to transfer to GOU#1&rsquo;s iCloud. Say what you want about Apple, but that part of their stuff works <em>really</em> well.</li>
<li>Left for Betty&rsquo;s Bay at about 16:00 with GOUs #1 and #2. The rest of the family already there.</li>
</ul>
<h2 id="sunday-2024-01-28">Sunday 2024-01-28</h2>
<ul>
<li>Woke up in Betty&rsquo;s Bay after a longer than normal night of sleep, but Garmin body battery was still not completely happy.</li>
<li>In spite of having run yesterday and still feeling a bit tired (see body battery above), I had the best run of the month so far in Betty&rsquo;s. Go figure.</li>
<li>Spent some time with Canva &ndash; what a great resource for doing nice designs, even flow charts &ndash; but not sure where I could use this.</li>
<li>Background thought through the past weeks, and mentioned on Tuesday: I would really like to do (and promite) more TIL-style writing at work and at home. See <a href="https://til.simonwillison.net/">Simon Willison&rsquo;s amazing TIL collection</a> for inspiration.</li>
<li>Ran into <a href="https://github.com/outlines-dev/outlines">https://github.com/outlines-dev/outlines</a> a Python library that can guarantee structured text generation from many LLMs, e.g. 100% valid JSON according to a specified schema. What makes it different from similar libraries? &ldquo;Unlike other libraries, regex-guided generation in Outlines is almost as fast as non-guided generation.&rdquo;</li>
<li>I already had <a href="https://github.com/microsoft/autogen">AutoGen</a> on my list for experimenting with multi-agent LLM applications, but now it has been joined by <a href="https://github.com/joaomdmoura/crewAI">crewAI</a> which I have also just ran into (thanks reddit!) and which seems to have significant support online.</li>
</ul>
 ]]></content:encoded></item><item><title>Daily Head Voices on Wednesday 2023-12-20</title><link>https://cpbotha.net/2023/12/22/daily-head-voices-on-wednesday-2023-12-20/</link><pubDate>Fri, 22 Dec 2023 12:13:00 +0200</pubDate><guid>https://cpbotha.net/2023/12/22/daily-head-voices-on-wednesday-2023-12-20/</guid><description> Morning run on the gravel road along the Serpentine river in Wilderness, probably one of my favourite routes ever. On a new wifi network with Apple TV, but forgot remote at home. Moved TV and Apple TV closer to AP to plug in via ethernet, which allowed the iPhone remote to connect, BUT Apple decided to be infuriating again: If your Apple TV has an Ethernet port, make sure your Apple TV isn&amp;rsquo;t connected to an Ethernet cable. If you&amp;rsquo;re using an Ethernet cable, you won&amp;rsquo;t see the option to connect to Wi-Fi. see https://support.apple.com/en-za/102346 &amp;ndash; this is of course a great big catch 22 for us at the moment. They do plenty of things right, but man, they make some really stupid mistakes. On a related note, it seems that before iOS 17, the Remote app on the iPhone was able to control the Apple TV even when they weren&amp;rsquo;t on the same WiFi network, see https://www.reddit.com/r/appletv/comments/16mo99d/apple_tv_remote_app_requires_a_wifi_connection_as/ On the other hand: Based on the following two recent publications, it really looks like Apple is cooking up something really interesting with large language models (LLMs): Apple announces ProTIP: Progressive Tool Retrieval Improves Planning &amp;ndash; so they are working on much improved ways of hooking up LLMs to tools, perhaps even on their devices? via https://twitter.com/_akhaliq/status/1736982938942677421 New Arxiv paper by Apple titled &amp;ldquo;LLM in a flash: Efficient Large Language Model Inference with Limited Memory&amp;rdquo; &amp;ndash; from the abstract: &amp;ldquo;These methods collectively enable running models up to twice the size of the available DRAM, with a 4-5x and 20-25x increase in inference speed compared to naive loading approaches in CPU and GPU, respectively. Our integration of sparsity awareness, context-adaptive loading, and a hardware-oriented design paves the way for effective inference of LLMs on devices with limited memory.&amp;rdquo; via https://www.threads.net/@sung.kim.mw/post/C1Dwx7Iypg4/ Spent some time digging into AppleScript (again) and how I could make a better orgmode to apple notes workflow Previous attempt is here: https://vxlabs.com/2018/10/29/importing-orgmode-notes-into-apple-notes/#bonus-round-convert-orgmode-buffer-to-apple-note-using-applescript The new flow should merge more cleverly with an existing folder in Notes, instead of re-importing the whole database each time</description><content:encoded><![CDATA[ <ul>
<li>Morning run on the gravel road along the Serpentine river in Wilderness, probably one of my favourite routes ever.</li>
<li>On a new wifi network with Apple TV, but forgot remote at home. Moved TV and Apple TV closer to AP to plug in via ethernet, which allowed the iPhone remote to connect, BUT Apple decided to be infuriating again: <em>If your Apple TV has an Ethernet port, make sure your Apple TV isn&rsquo;t connected to an Ethernet cable. If you&rsquo;re using an Ethernet cable, you won&rsquo;t see the option to connect to Wi-Fi.</em> see <a href="https://support.apple.com/en-za/102346">https://support.apple.com/en-za/102346</a> &ndash; this is of course a great big catch 22 for us at the moment.
<ul>
<li>They do plenty of things right, but man, they make some really stupid mistakes.</li>
<li>On a related note, it seems that before iOS 17, the Remote app on the iPhone was able to control the Apple TV even when they weren&rsquo;t on the same WiFi network, see <a href="https://www.reddit.com/r/appletv/comments/16mo99d/apple_tv_remote_app_requires_a_wifi_connection_as/">https://www.reddit.com/r/appletv/comments/16mo99d/apple_tv_remote_app_requires_a_wifi_connection_as/</a></li>
</ul>
</li>
<li>On the other hand: Based on the following two recent publications, it really looks like Apple is cooking up something really interesting with large language models (LLMs):
<ul>
<li>Apple announces ProTIP: Progressive Tool Retrieval Improves Planning &ndash; so they are working on much improved ways of hooking up LLMs to tools, perhaps even on their devices? via <a href="https://twitter.com/_akhaliq/status/1736982938942677421">https://twitter.com/_akhaliq/status/1736982938942677421</a></li>
<li>New Arxiv paper by Apple titled &ldquo;LLM in a flash: Efficient Large Language Model Inference with Limited Memory&rdquo; &ndash; from the abstract: &ldquo;These methods collectively enable running models up to twice the size of the available DRAM, with a 4-5x and 20-25x increase in inference speed compared to naive loading approaches in CPU and GPU, respectively. Our integration of sparsity awareness, context-adaptive loading, and a hardware-oriented design paves the way for effective inference of LLMs on devices with limited memory.&rdquo; via <a href="https://www.threads.net/@sung.kim.mw/post/C1Dwx7Iypg4/">https://www.threads.net/@sung.kim.mw/post/C1Dwx7Iypg4/</a></li>
</ul>
</li>
<li>Spent some time digging into AppleScript (again) and how I could make a better orgmode to apple notes workflow
<ul>
<li>Previous attempt is here: <a href="https://vxlabs.com/2018/10/29/importing-orgmode-notes-into-apple-notes/#bonus-round-convert-orgmode-buffer-to-apple-note-using-applescript">https://vxlabs.com/2018/10/29/importing-orgmode-notes-into-apple-notes/#bonus-round-convert-orgmode-buffer-to-apple-note-using-applescript</a></li>
<li>The new flow should merge more cleverly with an existing folder in Notes, instead of re-importing the whole database each time</li>
</ul>
</li>
</ul>
 ]]></content:encoded></item><item><title>Weekly Head Voices #253: Weekend Warrior</title><link>https://cpbotha.net/2023/09/02/weekly-head-voices-253-weekend-warrior/</link><pubDate>Sat, 02 Sep 2023 16:38:00 +0200</pubDate><guid>https://cpbotha.net/2023/09/02/weekly-head-voices-253-weekend-warrior/</guid><description>Welcome back everyone!
It&amp;rsquo;s clear to me that I have to get back in the WHV saddle, but preaching sure is easier than practising, and so I thought it might be a good idea to try and bullet-list myself back into it.
(When I say &amp;ldquo;bullet-list&amp;rdquo; I mean &amp;ldquo;helpfully named hierarchical sections&amp;rdquo;, because Emacs tends to frown quite disapprovingly at mere bullet lists. Here I am after the intention of the bullet-list, namely to just get on with it.)</description><content:encoded><![CDATA[ <p>Welcome back everyone!</p>
<p>It&rsquo;s clear to me that I have to get back in the WHV saddle, but preaching sure
is easier than practising, and so I thought it might be a good idea to try and
<a href="/tags/bullet-lists/">bullet-list</a> myself back into it.</p>
<p>(When I say &ldquo;bullet-list&rdquo; I mean &ldquo;helpfully named hierarchical sections&rdquo;,
because <a href="/tags/emacs/">Emacs</a> tends to frown quite disapprovingly at mere bullet lists. Here I
am after the <em>intention</em> of the bullet-list, namely to <em>just get on with it</em>.)</p>










<figure><a href="bilthoven_manege.jpg">
    <img
        
            sizes="(min-width: 35em) 1200px, 100vw"
              
            srcset='
            
                
                https://cpbotha.net/2023/09/02/weekly-head-voices-253-weekend-warrior/bilthoven_manege_hu_2e0173759a9b3934.jpg 480w,
            
                
                https://cpbotha.net/2023/09/02/weekly-head-voices-253-weekend-warrior/bilthoven_manege_hu_1740715dbd8e6fe0.jpg 800w,
            
                
                https://cpbotha.net/2023/09/02/weekly-head-voices-253-weekend-warrior/bilthoven_manege_hu_3893d5e642d52f69.jpg 1200w,
            
                
                https://cpbotha.net/2023/09/02/weekly-head-voices-253-weekend-warrior/bilthoven_manege_hu_31349c7dd6e8518e.jpg 1500w,
            '

            
            
            src="https://cpbotha.net/2023/09/02/weekly-head-voices-253-weekend-warrior/bilthoven_manege_hu_1740715dbd8e6fe0.jpg"
            

        
            alt="Figure 1: Manege from a late summer stroll in NL. Smells, sounds, weather took me back so hard."/> </a><figcaption>
            <p><span class="figure-number">Figure 1: </span>Manege from a late summer stroll in NL. Smells, sounds, weather took me back so hard.</p>
        </figcaption>
</figure>

<p>It is important to mention that this post attempts to cover time up to
Wednesday, August 23, 2023.</p>
<h2 id="running">Running</h2>
<p>My running habit has been steadily returning to its pre-op state, both in terms of
fitness but, more importantly, in terms of joy.</p>
<p>Also, my sixth pair of Altra Escalantes (version 3.0) recently arrived. I
wanted black ones, as I usually recycle old Altras after their recommended
700km or so into super comfortable office shoes, but my supplier was out of
stock and so I ended up with these surprisingly attractive blue and red ones:</p>










<figure><a href="altra_escalante_v3_no6.jpg">
    <img
        
            sizes="(min-width: 35em) 1200px, 100vw"
              
            srcset='
            
                
                https://cpbotha.net/2023/09/02/weekly-head-voices-253-weekend-warrior/altra_escalante_v3_no6_hu_c8d1293b0b36ab.jpg 480w,
            
                
                https://cpbotha.net/2023/09/02/weekly-head-voices-253-weekend-warrior/altra_escalante_v3_no6_hu_a5aea862418ea2ec.jpg 800w,
            
                
                https://cpbotha.net/2023/09/02/weekly-head-voices-253-weekend-warrior/altra_escalante_v3_no6_hu_230eb4b8efe70307.jpg 1200w,
            
                
                
            '

            
            
            src="https://cpbotha.net/2023/09/02/weekly-head-voices-253-weekend-warrior/altra_escalante_v3_no6_hu_a5aea862418ea2ec.jpg"
            

         width="50%"/> </a>
</figure>

<p>In more good news, it turns out that it&rsquo;s <a href="https://www.webmd.com/fitness-exercise/news/20230719/your-heart-benefits-even-if-you-exercise-as-a-weekend-warrior">entirely OK if you spend all of your
minimum of 2.5 weekly hours of exercise during the weekend</a>.</p>
<p>Personally, I usually manage to fit in two shorter runs during the week, and a
longer run during the weekend, for a desired total of 25km per week, but I have
always wondered if it was in fact required to exercise on every day of the week
for maximal health benefit.</p>
<p>P.S. My main motivation is the unqualified joy of the run and not so much the
health benefits, although the benefits sure are nice!</p>
<p>P.P.S. <a href="/2023/01/01/the-2022-to-2023-transition-post/#running">25km per week was my resolution for 2023</a>, but that plan was quite rudely
torpedoed by my <a href="/2023/07/01/weekly-head-voices-252-prostate-cancer/">prostate cancer adventure a few months ago</a>, so now I just try
to make it week by week.</p>
<h2 id="genai">GenAI</h2>
<p>For the past months, I&rsquo;ve been going deeper and deeper into generative AI, and
more specifically large language models (LLMs), down to the nuts and bolts and
let&rsquo;s-get-Llama-2-70-billion-quantized-and-running-on-my-PC levels.</p>
<p>Here are a few things that I really liked learning about:</p>
<ul>
<li>Although it has indeed been a longer journey, the current GenAI explosion /
hype seems to have been ignited in the third quarter of 2022, with the open
source release of Stable Diffusion in August, and the birth of ChatGPT in
November.</li>
<li>For the largest part, the most powerful LLMs have been trained, on hundreds
of billions to trillions of words, how to predict the next / missing word of
an incomplete document. After enough of this, they appear to gain some sort
of reasoning capability, including being able to answer theory of mind
questions.
<ul>
<li>There are striking similarities to how humans interpret speech.</li>
</ul>
</li>
<li>Almost all of the currently famous models (Stable Diffusion, Whisper, all
current LLMs) are based on a specific type of neural network called a
Transformer, introduced in the paper <em>Attention Is All You Need</em>, published by
Ashish Vaswani and fellow Google researchers in 2017.</li>
</ul>
<p>For many more details about these, and other hopefully interesting
observations, please come to one of my GenAI talks!</p>
<p>GenAI developments are continuing at a truly impressive pace, and now I hope
that we (personally) can also start showing some practical and useful
applications!</p>
<p>P.S. Read the brilliant Lyn Alden&rsquo;s latest newsletter <a href="https://www.lynalden.com/august-2023-newsletter/">Six AI Themes to Consider</a>
in which she discusses how AIs (actually LLMs) are already starting to use
bitcoin (lightning) to pay for services (soon other AIs and also humans) in
order to complete their tasks.</p>
<h2 id="lowlands-2023">Lowlands 2023</h2>
<p>One could say that the WHV series owes its life to a certain 3-day festival in
the Netherlands as <a href="/2009/08/29/starting-today-head-voices-every-week/">it was born in the sweet afterglow of the 2009 edition</a>.</p>
<p>However, due to the strict WHALLSALL privacy policy, you will find only
<a href="/tags/lowlands/">pleasant echoes of the experience</a> in a number of posts on this blog.</p>
<p>This time it felt even more special, because it&rsquo;s the first time that I was
able to go since <a href="/2019/09/01/weekly-head-voices-176-cycle-of-life/">all the way back in 2019</a>.</p>
<p>I was pleasantly shocked by the warm <em>familiarity</em> of my other home, starting all
the way from the airport in Cape Town, joining hundreds of Dutchies returning
home after their vacations in SA, to arriving in NL and letting that lovely
language permeate my neural network, all through the festival chaos and
sometimes extremely close proximity to tens of thousands of locals, to walking
and cycling under the late summer sun, to spending the highest possible quality
time with my friends there.</p>
<p>Again I am left overflowing with gratitude.</p>
<p>Thank you other home, and eternal thank you friends!</p>
<h2 id="i-am-a-function">I am a function</h2>
<p>Back in <a href="/2014/05/07/weekly-head-voices-70-patterns-in-the-sand/">WHV #70 from 2014</a>, based on some reading about the turnover of matter
in humans, I came to the following conclusion:</p>
<blockquote>
<p>Now I see us all as nothing more than the continuously changing patterns that
form briefly in the grains of sand of the universe. Winds blow grains of sand
around, now taking part in one pattern and then in another. At some point, your
body has contained parts of your best friend, and of your worst enemy. The
patterns change continually; sometimes they fade away, and sometimes new
patterns emerge.</p>
</blockquote>
<p>In the intervening years, reader KvG first introduced me to <a href="https://en.wikipedia.org/wiki/Alan_Watts">Alan Watts</a>, noting
that they saw similar themes in our writing.</p>
<p>I am wording it carefully here, as I obviously can&rsquo;t really compare my backyard
philosophical attempts to the work of Alan Watts, which I have now come to know
better.</p>
<p>That story was required to bring us to this, the concluding quote of this post:</p>
<blockquote>
<p>You are a function of what the whole universe is doing in the same way that a
wave is a function of what the whole ocean is doing. &ndash; Alan Watts</p>
</blockquote>
<p>I really love that.</p>
 ]]></content:encoded></item></channel></rss>