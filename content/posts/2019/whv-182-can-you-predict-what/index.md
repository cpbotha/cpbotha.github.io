---
title: "Weekly Head Voices #182: Can you predict what ..."
slug: "weekly-head-voices-182-can-you-predict-what"
date: 2019-11-04T22:05:00+02:00
tags:
  - idealism
  - language models
  - mont marie
  - natural language processing
  - neural networks
  - visweek
categories:
  - weekly head voices
type: "post"
---

Welcome to your home away from home folks!

This, the one hundred and eighty second edition of the WHV, looks back at the
three weeks from Monday October 14 to Sunday November 3, 2019.

<figure>
{{< img src="mont_marie_view_from_lunch.jpg" link="true" >}}
<figcaption>
One of the beautiful views from our Sunday (October 20) lunch at Mont Marie in Stellenbosch.
</figcaption>
</figure>

## On attempting to publish the WHV on a weekly basis.

Somewhere at the end of the first week, I sat down to write, but I soon
realised that I didn't have all that much to say.

Ironically, earlier that day I had had an online discussion where I made the
statement that I preferred putting out posts regularly, rather than waiting
until until I had something "really good" to publish.

In the latter case, one tends to let things slip further and further, with that
great internal excuse that one's ideas and writing do not yet satisfy one's
otherwise unspecified but high standards.

In addition, one's performance anxiety is now fueled into a frenzy by the
illusion that surely the expectations of one's audience are growing greater by
the minute, and hence the next post will be measured even more strictly against
the mythical yard stick of blog posts that in reality very few people, mostly
friends, actually take the time to read.

So that happened.

As is the case with many other things in life that seem to follow the Sisyphean
ideal, I have made peace with the fact that I will just continue working at
this, until the end.

## A call from the future.

I made three longer term technology-themed bets with friends and colleagues at
the IEEE VisWeek conference in 2009.

The idea was that the first of the three would play out and finally be
evaluated at VisWeek 2019 (10 years later), and the other two more or less 20
years later, to be decided at Visweek 2029.

Fortunately I wrote the bets up in a blog post, all the way back in 2009,
titled [Futuristic Betting at VisWeek
2009](/2009/10/18/futuristic-betting-at-visweek-2009/).

To my surprise, but far more to my delight, an overlapping subset of the
involved friends and colleagues recorded an hour-long video message at [VisWeek
2019 in Vancouver](http://ieeevis.org/year/2019/welcome) and sent it to me via
the YouTubes.

The main message of their video was that I had lost bet #1, with which I could
agree, and that they had their doubts about my chances in bets #2 and #3, with
which I can not yet agree.

You can read [the addendum I made to the original blog
post](/2009/10/18/futuristic-betting-at-visweek-2009/#update-on-2019-10-27) for
all of the details.

When I made those predictions, confident that we would be able to debate and
laugh about them at those future conferences, I ironically had no idea that my
life was going to take the turns that it did, [out of
academia](/2013/03/09/dear-academia-i-hope-we-can-still-be-friends/) and
shortly thereafter [out of Europe](/2013/12/14/on-leaving-the-netherlands/).

Fortunately, that futuristic betting blog post seems to have functioned as a
sort of anchor in the sands of time, playing its small part in making the
connection from 2009 to 2019, from Atlantic City to Vancouver and even to
Somerset West.

What will happen in 2029?

## Humans predicting the world in real-time.

Based on [this recent EEG-based experimental
study](https://www.eurekalert.org/pub_releases/2019-10/sisd-py101419.php), it
sounds like our brains are continuously predicting the next word that someone
we're in conversation with is going to say.

Especially in noisy environments, such as IN DA CLUB, this helps us to
understand what our conversation partners are saying.

What struck me when I read the linked press release, and shortly thereafter
tried to assimilate [the full
article](https://www.eneuro.org/content/6/5/ENEURO.0128-19.2019), quite
attractively titled *Neural Signal to Violations of Abstract Rules Using
Speech-Like Stimuli*, was that is exactly what computer-based language models
do.

*Language models* are mathematical constructs, which mostly live in software,
that attempt to predict the next word in a sentence, based on the previous
words in a sequence.

Recently, [deep learning approaches overtook the more classical statistical
approaches for building such language
models](http://www.fit.vutbr.cz/research/groups/speech/publi/2010/mikolov_interspeech2010_IS100722.pdf).

Given a few thousand articles in French for example, a neural network can learn
how to predict the next word in any given French sentence with high accuracy.

Together with the fact that the internet is now overflowing with examples of
many human languages, anyone with some spare time and GPU cycles to burn can
train up a language model, or even download a pre-trained example.

Such a language model can then be
[fine-tuned](https://arxiv.org/abs/1801.06146) for other language tasks such as
sentiment analysis and topic classification.

I enjoyed seeing this (growing) similarity between our built-in language
processing wetware and the rapidly developing world of deep learning.

Maybe you did too.

Just a little bit.

<figure>
{{< img src="mont_marie_clouds2.jpg" link="true" >}}
<figcaption>
My phone camera definitely needs more of that DeepFusion to capture the amazing
contrast patterns that these particular clouds were displaying at that
moment. You're going to have to take my word for it.
</figcaption>
</figure>
